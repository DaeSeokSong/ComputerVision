{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/image-processing/blob/feature%2FPreprocessing/Preprocessor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install**"
      ],
      "metadata": {
        "id": "rmvVB2P2aWlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZNy7tJjaUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_SoWfFhxL0-"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xpg4AUPixNrD"
      },
      "outputs": [],
      "source": [
        "# Image processing\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "\n",
        "# ETC\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OHL2n1YxlH_"
      },
      "source": [
        "## Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxOqA3DpxlgC",
        "outputId": "4059786f-f9ed-42a2-d5f7-289a38113995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqwTBfCyxm3v",
        "outputId": "b677e1da-4cf9-45f4-e451-935a1ea6feeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\n",
            "total 11032\n",
            "drwx------ 2 root root     4096 Sep 14 08:50 'Case Report'\n",
            "drwx------ 2 root root     4096 Aug 16 08:53  Dataset\n",
            "-rw------- 1 root root    47630 Sep 23 11:31 '[Down Sampling] Surgical-Wound UNet.ipynb'\n",
            "drwx------ 2 root root     4096 Sep 14 13:17  Lagacy\n",
            "drwx------ 2 root root     4096 Aug 17 05:49  Log\n",
            "-rw------- 1 root root    84314 Sep 23 17:09  Preprocessor.ipynb\n",
            "drwx------ 2 root root     4096 Sep 14 06:04 'Raw Dataset'\n",
            "-rw------- 1 root root 10999888 Sep 23 17:03 'Surgical-Wound UNet.ipynb'\n",
            "-rw------- 1 root root   142540 Sep 23 04:36  Tester.ipynb\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoO0sORTxEIQ"
      },
      "source": [
        "# **Grobal variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z9c_qcr4xHQR"
      },
      "outputs": [],
      "source": [
        "# Path (Absolute path in essential)\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\"\n",
        "\n",
        "RAW_DATA_PATH = \"/Raw Dataset\"\n",
        "\n",
        "WOUND_TRAIN_PATH = \"/Wound/train\"\n",
        "WOUND_TEST_PATH = \"/Wound/test\"\n",
        "CVC_INPUT_PATH = \"/CVC-clinicDB/Original\"\n",
        "CVC_GT_PATH = \"/CVC-clinicDB/Ground Truth\"\n",
        "\n",
        "DATASET_PATH = \"/Dataset\"\n",
        "\n",
        "IMAGES_PATH = '/images'\n",
        "LABELS_PATH = '/labels'\n",
        "\n",
        "# Image preprocess\n",
        "NORM_INPUT_W_SIZE = 224\n",
        "NORM_INPUT_H_SIZE = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttpnk92dc7Je"
      },
      "source": [
        "# **Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8pYDBzLPc8W2"
      },
      "outputs": [],
      "source": [
        "def imshow_waitkey_enter(image):\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    input(\"Please press the Enter key to proceed\\n\")\n",
        "    output.clear()\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9mVlktdB-A"
      },
      "source": [
        "# **Make dir**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c3JXzvP6dDFA"
      },
      "outputs": [],
      "source": [
        "# Create processed dataset dir\n",
        "train_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'train')\n",
        "val_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'val')\n",
        "test_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'test')\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4AWru7Aflb"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# ***Preprocess Performace Compare Test***\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "***공통사항***\n",
        "* 원본 이미지 크기 = 224 * 224\n",
        "* epoch = 100\n",
        "* batch = 8\n",
        "> UNet batch size = 4<br>\n",
        "> Wound dataset batch size = 8\n",
        "* lr = 1e-3\n",
        "* Train:Val = 7:3\n",
        "* Used model = Polar Res UNet++ (ISIC 2018 dice scroe rank no.1)\n",
        "\n",
        "<br>\n",
        "\n",
        "***주의사항***\n",
        "* 이미지의 사이즈는 정규화 되어야 한다.\n",
        "* Convolution에서 특징점을 잘 추출하기 때문에 색상영역이나, 스무딩/샤프닝 같은 필터 처리는 되려 성능저하 요소가 될 수 있다. \n",
        "\n",
        "<br>\n",
        "\n",
        "***참고사항***\n",
        "* CNN 대표 모델들의 네트워크 입력 사이즈는 224 * 224\n",
        "* 이미지의 사이즈가 큰 경우에, Overlap-Tite(down sampling) 전략으로 한 이미지를 나눠서 학습시킨다.\n",
        "\n",
        "<br>\n",
        "\n",
        "***현재 결과***\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## [***Control Group***](https://www.nature.com/articles/s41598-020-78799-w)\n",
        "> [Train code](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/train.py)\n",
        "> <br>\n",
        "> [Data generator](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/utils/io/data.py#L10)\n",
        "> <br>\n",
        "> <br>\n",
        "> Raw dataset에 대한 전처리 없이, load 후 model에 들어가기 전에 Normalize\n",
        "> <br>\n",
        "> * 현재까지 대조군 성능을 넘은 실험군이 없다.\n",
        "\n",
        "```\n",
        "model = Deeplabv3(input_shape=(input_dim_x, input_dim_y, 3), classes=1)\n",
        "```"
      ],
      "metadata": {
        "id": "iuMgswybTBIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance"
      ],
      "metadata": {
        "id": "d8_SlWxvUPng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0460 | BATCH  073 /  073 | DICE LOSS  0.0402\n",
        "TRAIN || EPOCH 0461 | BATCH  073 /  073 | DICE LOSS  0.0424\n",
        "TRAIN || EPOCH 0462 | BATCH  073 /  073 | DICE LOSS  0.0406\n",
        "TRAIN || EPOCH 0463 | BATCH  073 /  073 | DICE LOSS  0.0432\n",
        "TRAIN || EPOCH 0464 | BATCH  073 /  073 | DICE LOSS  0.0401\n",
        "\n",
        "VALID || EPOCH 0460 | BATCH  032 /  032 | DICE LOSS  0.1069\n",
        "VALID || EPOCH 0461 | BATCH  032 /  032 | DICE LOSS  0.1103\n",
        "VALID || EPOCH 0462 | BATCH  032 /  032 | DICE LOSS  0.1140\n",
        "VALID || EPOCH 0463 | BATCH  032 /  032 | DICE LOSS  0.1140\n",
        "VALID || EPOCH 0464 | BATCH  032 /  032 | DICE LOSS  0.1146\n",
        "\n",
        "Best loss in Train =  0.0392\n",
        "Best loss in Validation =  0.0891\n",
        "```"
      ],
      "metadata": {
        "id": "EgfvjWMBDSD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1rG2arJcirP5erpfMvdt-vL3Gp6ArSlka\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1U43nlSo67GlVrQZZ7Gos74nxwTgvrjEY\"  width = 1080>"
      ],
      "metadata": {
        "id": "Sy-K9hGPCUCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arrange dataset\n",
        "> Not change anything about input image(scar)"
      ],
      "metadata": {
        "id": "LAOzIhbp7gxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    wound = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), wound)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    wound = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), wound)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    wound = cv2.imread(gt)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), wound)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "UdLe04Tt7MDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## ***Experimental Group***"
      ],
      "metadata": {
        "id": "sHPbY0FsOzj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 1\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Wound Image to (224, 224)"
      ],
      "metadata": {
        "id": "QcitBtU5PAHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "0meRCPq8wdFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=\"  width = 1080>"
      ],
      "metadata": {
        "id": "RxXI8AHs0BFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "yltgxr4jxHZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                          (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                          (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "ON4nZrW6OWjE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 2\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Pad the rest part to (224, 224) based on the middle of the image"
      ],
      "metadata": {
        "id": "ZzgNKc_5QSFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1058\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1062\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1061\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1057\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1052\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.1309\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.1308\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.1356\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.1357\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.1401\n",
        "\n",
        "Best loss in Train =  0.0920\n",
        "Best loss in Validation =  0.1044\n",
        "```"
      ],
      "metadata": {
        "id": "5TRurS-tps6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1FqoLg0DMZwS0HtYXCfpn113oQvvU_Fic\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1j18BDF10_gfpgkYl_H0QZbPAdK4w1Px8\"  width = 640>"
      ],
      "metadata": {
        "id": "2WiLXx1IqCtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "Iz17E2XaqDrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "YwmhVRrxOXMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 3\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Wound Image to (224, 224) in proportion to the maximum ratio\n",
        "3. Pad the rest part to (224, 224) in the direction of right/down "
      ],
      "metadata": {
        "id": "SJ_zsDTRPTNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1401\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1395\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1397\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1393\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1425\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.1842\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.1921\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.1916\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.1882\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.1842\n",
        "\n",
        "Best loss in Train =  0.1257\n",
        "Best loss in Validation =  0.1525\n",
        "```"
      ],
      "metadata": {
        "id": "k-aQeDdTB1pL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1Hz_tdEFXE9I8LqIfro3anAOw8RxbkjKS\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1ahoz3Wke5MKGqa55x9TEnejgElTM-5Pw\"  width = 640>"
      ],
      "metadata": {
        "id": "GfUeBkdVB49d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "AtBTf-D8CSwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "vuXr6qGyOXje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 4\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Wound Image to (224, 224) in proportion to the maximum ratio\n",
        "3. Pad the rest part to (224, 224) based on the middle of the image"
      ],
      "metadata": {
        "id": "Lm8__jJHPrdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1341\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1343\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1336\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1329\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1329\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.1811\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.1797\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.1756\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.1734\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.1747\n",
        "\n",
        "Best loss in Train =  0.1261\n",
        "Best loss in Validation =  0.1446\n",
        "```"
      ],
      "metadata": {
        "id": "gqrfPpWr-OaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1ldhepTNZHrtIerQfm4jjEa6SIph9xo-X\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1-doK7qAEUSmic6YweHXnI5s2jXGcglBO\"  width = 640>"
      ],
      "metadata": {
        "id": "XwvA6VmH-hHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "H-DNlgcm-dYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    if resize_criteria == 0: # criteria is width\n",
        "        pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    # Calculate padding size\n",
        "    elif resize_criteria == 1: # criteria is heigth\n",
        "        pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Print resize error\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    if resize_criteria == 0: # criteria is width\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    # Calculate padding size\n",
        "    elif resize_criteria == 1: # criteria is heigth\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Print resize error\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    if resize_criteria == 0: # criteria is width\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    # Calculate padding size\n",
        "    elif resize_criteria == 1: # criteria is heigth\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Print resize error\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "T8N95OYCOX6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 5\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Wound Image to (204, 204) in proportion to the maximum ratio\n",
        "3. Pad the rest part to (224, 224) based on the middle of the image"
      ],
      "metadata": {
        "id": "0azgBDw_3R-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1232\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1237\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1236\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1232\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1225\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.1741\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.1717\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.1719\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.1738\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.1694\n",
        "\n",
        "Best loss in Train =  0.1165\n",
        "Best loss in Validation =  0.1489\n",
        "```"
      ],
      "metadata": {
        "id": "QB42zXzbAnRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=18o_acrSOCWL5oO-Q4haKxhJ-8cwsdgtr\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1vaB5sZaRGzBRUJX62Sbi9icL-pggkaxu\"  width = 640>"
      ],
      "metadata": {
        "id": "sNjqdAjIAr-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "n_Ijqr-cAsre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (204, 204) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = (NORM_INPUT_W_SIZE - 20) / width\n",
        "    resize_scale_h = (NORM_INPUT_H_SIZE - 20) / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "    pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "        \n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "\n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (204, 204) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = (NORM_INPUT_W_SIZE - 20) / width\n",
        "    resize_scale_h = (NORM_INPUT_H_SIZE - 20) / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "    pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "        \n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "\n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (204, 204) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = (NORM_INPUT_W_SIZE - 20) / width\n",
        "    resize_scale_h = (NORM_INPUT_H_SIZE - 20) / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "    pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "        \n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "\n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "jo09GwRG3gMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# BACKUP"
      ],
      "metadata": {
        "id": "u-wD1EFEZ0Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_divisors(n):\n",
        "    data = []\n",
        "\n",
        "    divisor = 2\n",
        "    while(divisor <= n):\n",
        "        if n % divisor == 0:\n",
        "            data.append(divisor)\n",
        "\n",
        "        divisor = divisor * 2\n",
        "            \n",
        "    return data\n",
        "\n",
        "# Init image index\n",
        "w_idx = 0\n",
        "gt_idx = 0\n",
        "\n",
        "# Easy Max Adaptive Sliding Window\n",
        "    # 1. feature_size의 약수 중 2의 배수를 계산하여 divisors에 저장한다.\n",
        "    # 2. divisors 안의 숫자 중 가장 큰수를 골라 stride라고 정의한다.\n",
        "    # 3. 기준 축(refer_axis)이 아닌 축의 길이를 slide_size라고 정의한다.\n",
        "    # 4. (slide_size-feature_size) // stride를 계산하여 step_num으로 정의한다.\n",
        "    # 5. (slide_size-feature_size) % stride를 계산하여 remain_pixel으로 정의한다.\n",
        "    # 6. remain_pixel // step_num을 계산하여 extra_stride로 정의한다.\n",
        "    # 7. remain_pixel % step_num을 계산하여 extra_random_stride로 정의한다.\n",
        "    # 8. stride = stride + extra_stride\n",
        "    # 9. extra_random_stride != 0이라면, 각 stride에 맞게 slide window를 진행하면서 랜덤하게 적어도 1번은 해당 step의 stride에 extra_random_stride를 더한다.\n",
        "    # 10. window ROI의 (전체 픽셀-noneZeroCount)를 비교하여 gt의 흰색 픽셀 비율이 5% 미만이면 건너뛴다.\n",
        "\n",
        "# 0.\n",
        "feature_size = 224\n",
        "\n",
        "# 1.\n",
        "divisors = get_divisors(224)\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w > resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Calc white pixel in ground-truth for check proposed data\n",
        "    gt_pixel_num = cv2.countNonZero(gt_image)\n",
        "    if gt_pixel_num == 0: continue\n",
        "\n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 2.\n",
        "    stride = max(divisors)\n",
        "\n",
        "    # 3.\n",
        "    if height > width:\n",
        "        assert width == feature_size, \"Preprocessed image width is wrong, train[\" + str(idx) + \"] width is \" + str(width)\n",
        "\n",
        "        refer_axis = 'x'\n",
        "        slide_size = height\n",
        "    else:\n",
        "        assert height == feature_size, \"Preprocessed image width is height, train[\" + str(idx) + \"] height is \" + str(height)\n",
        "            \n",
        "        refer_axis = 'y'\n",
        "        slide_size = width\n",
        "\n",
        "    # 4.\n",
        "    step_num = (slide_size - feature_size) // stride\n",
        "    if step_num == 0:\n",
        "        cv2.imwrite(os.path.join(train_dir, f'wound_{w_idx:04d}.png'), image)\n",
        "        cv2.imwrite(os.path.join(train_dir, f'gt_{gt_idx:04d}.png'), gt_image)\n",
        "\n",
        "        w_idx += 1\n",
        "        gt_idx += 1\n",
        "\n",
        "        continue\n",
        "\n",
        "    # 5.\n",
        "    remain_pixel = (slide_size - feature_size) % stride\n",
        "\n",
        "    # 6.\n",
        "    extra_stride = remain_pixel // (step_num + 1)\n",
        "\n",
        "    # 7.\n",
        "    extra_random_stride = remain_pixel % (step_num + 1)\n",
        "    extra_idx = random.randrange(0, (step_num + 1))\n",
        "\n",
        "    # 8.\n",
        "    stride += extra_stride\n",
        "\n",
        "    # 9.\n",
        "    images = []\n",
        "    gt_images = []\n",
        "    for step in range(0, step_num+1):\n",
        "        tmp_stride = stride\n",
        "\n",
        "        if extra_random_stride > 0 and step == extra_idx:\n",
        "            tmp_stride += extra_random_stride\n",
        "            extra_random_stride = -1 * extra_random_stride\n",
        "\n",
        "        start_idx = tmp_stride * step\n",
        "        end_idx = (tmp_stride * step) + feature_size\n",
        "        if extra_random_stride < 0 and step != extra_idx:\n",
        "            start_idx += extra_random_stride * (-1)\n",
        "            end_idx += extra_random_stride * (-1)\n",
        "\n",
        "        if refer_axis == 'x':\n",
        "            slide_gt = gt_image[start_idx:end_idx, :]\n",
        "            cnt_white_px = cv2.countNonZero(slide_gt)\n",
        "\n",
        "            # 10.\n",
        "            if cnt_white_px / gt_pixel_num > 0.05:\n",
        "                images.append(image[start_idx:end_idx, :, :])\n",
        "                gt_images.append(slide_gt)\n",
        "\n",
        "        elif refer_axis == 'y':\n",
        "            slide_gt = gt_image[:, start_idx:end_idx]\n",
        "            cnt_white_px = cv2.countNonZero(slide_gt)\n",
        "\n",
        "            # 10.\n",
        "            if cnt_white_px / gt_pixel_num > 0.05:\n",
        "                images.append(image[:, start_idx:end_idx, :])\n",
        "                gt_images.append(slide_gt)\n",
        "\n",
        "        else:\n",
        "            assert True, \"CODE ERROR, choice reference axis\"\n",
        "\n",
        "    # Save normalized image\n",
        "    for wound in images:\n",
        "        cv2.imwrite(os.path.join(train_dir, f'wound_{w_idx:04d}.png'), wound)\n",
        "        w_idx += 1\n",
        "\n",
        "    for ground_truth in gt_images:\n",
        "        cv2.imwrite(os.path.join(train_dir, f'gt_{gt_idx:04d}.png'), ground_truth)\n",
        "        gt_idx += 1"
      ],
      "metadata": {
        "id": "xteVx_24Z2hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 6\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Wound Image to 224 based on the smaller size(row or column), keeping the proportion\n",
        "3. Sampling by moving the kernel both on input and ground-truth"
      ],
      "metadata": {
        "id": "apS4MTgAQaez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "25xfM8Od3GLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1ldhepTNZHrtIerQfm4jjEa6SIph9xo-X\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1-doK7qAEUSmic6YweHXnI5s2jXGcglBO\"  width = 640>"
      ],
      "metadata": {
        "id": "oWbkMepc3IKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "7SsUgc513JlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w > resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w > resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w > resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "ZOrpZ1h7OYZx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EgfvjWMBDSD0",
        "LAOzIhbp7gxx",
        "5TRurS-tps6H",
        "Iz17E2XaqDrv",
        "k-aQeDdTB1pL",
        "AtBTf-D8CSwi",
        "gqrfPpWr-OaT",
        "H-DNlgcm-dYU",
        "QB42zXzbAnRv",
        "n_Ijqr-cAsre",
        "u-wD1EFEZ0Ha",
        "apS4MTgAQaez",
        "25xfM8Od3GLz",
        "oWbkMepc3IKD"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMHtUQJMXvCtiiR+Z+Xn3GY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}