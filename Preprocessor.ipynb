{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/image-processing/blob/feature%2FPreprocessing/Preprocessor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install**"
      ],
      "metadata": {
        "id": "rmvVB2P2aWlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZNy7tJjaUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_SoWfFhxL0-"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpg4AUPixNrD"
      },
      "outputs": [],
      "source": [
        "# Image processing\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "\n",
        "# ETC\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OHL2n1YxlH_"
      },
      "source": [
        "## Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxOqA3DpxlgC",
        "outputId": "624db91e-fa5b-4d98-aa90-124b136a82fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqwTBfCyxm3v",
        "outputId": "970b0672-781b-4054-9900-56fc6ee1c258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\n",
            "total 10791\n",
            "drwx------ 6 root root     4096 Sep 14 08:50 'Case Report'\n",
            "drwx------ 2 root root     4096 Sep 16 14:22  Dataset\n",
            "drwx------ 2 root root     4096 Sep 14 13:17  Lagacy\n",
            "drwx------ 2 root root     4096 Aug 17 05:49  Log\n",
            "-rw------- 1 root root    65731 Sep 16 16:02  Preprocessor.ipynb\n",
            "drwx------ 3 root root     4096 Sep 14 06:04 'Raw Dataset'\n",
            "-rw------- 1 root root 10922999 Sep 16 15:58 'Surgical-Wound Unet.ipynb'\n",
            "-rw------- 1 root root    39995 Aug 15 11:40 'UNet architecture.PNG'\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoO0sORTxEIQ"
      },
      "source": [
        "# **Grobal variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9c_qcr4xHQR"
      },
      "outputs": [],
      "source": [
        "# Path\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\"\n",
        "\n",
        "RAW_DATA_PATH = \"/Raw Dataset\"\n",
        "\n",
        "WOUND_TRAIN_PATH = \"/Wound/train\"\n",
        "WOUND_TEST_PATH = \"/Wound/test\"\n",
        "CVC_INPUT_PATH = \"/CVC-clinicDB/Original\"\n",
        "CVC_GT_PATH = \"/CVC-clinicDB/Ground Truth\"\n",
        "\n",
        "DATASET_PATH = \"/Dataset\"\n",
        "\n",
        "IMAGES_PATH = '/images'\n",
        "LABELS_PATH = '/labels'\n",
        "\n",
        "# Image preprocess\n",
        "NORM_INPUT_W_SIZE = 224\n",
        "NORM_INPUT_H_SIZE = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttpnk92dc7Je"
      },
      "source": [
        "# **Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pYDBzLPc8W2"
      },
      "outputs": [],
      "source": [
        "def imshow_waitkey_enter(image):\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    input(\"Please press the Enter key to proceed\\n\")\n",
        "    output.clear()\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9mVlktdB-A"
      },
      "source": [
        "# **Make dir**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3JXzvP6dDFA"
      },
      "outputs": [],
      "source": [
        "# Create processed dataset dir\n",
        "train_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'train')\n",
        "val_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'val')\n",
        "test_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'test')\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4AWru7Aflb"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# ***Preprocess Performace Compare Test***\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "***공통사항***\n",
        "* 원본 이미지 크기 = 224 * 224\n",
        "* epoch = 100\n",
        "* batch = 8\n",
        "> UNet batch size = 4<br>\n",
        "> Wound dataset batch size = 8\n",
        "* lr = 1e-3\n",
        "* Train:Val = 7:3\n",
        "* Used model = Polar Res UNet++ (ISIC 2018 dice scroe rank no.1)\n",
        "\n",
        "<br>\n",
        "\n",
        "***주의사항***\n",
        "* 이미지의 사이즈는 정규화 되어야 한다.\n",
        "* Convolution에서 특징점을 잘 추출하기 때문에 색상영역이나, 스무딩/샤프닝 같은 필터 처리는 되려 성능저하 요소가 될 수 있다. \n",
        "\n",
        "<br>\n",
        "\n",
        "***참고사항***\n",
        "* CNN 대표 모델들의 네트워크 입력 사이즈는 224 * 224\n",
        "* 이미지의 사이즈가 큰 경우에, Overlap-Tite(down sampling) 전략으로 한 이미지를 나눠서 학습시킨다.\n",
        "\n",
        "<br>\n",
        "\n",
        "***현재 결과***\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## [***Control Group***](https://www.nature.com/articles/s41598-020-78799-w)\n",
        "> [Train code](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/train.py)\n",
        "> <br>\n",
        "> [Data generator](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/utils/io/data.py#L10)\n",
        "> <br>\n",
        "> <br>\n",
        "> Raw dataset에 대한 전처리 없이, load 후 model에 들어가기 전에 Normalize\n",
        "> <br>\n",
        "> * 현재까지 대조군 성능을 넘은 실험군이 없다.\n",
        "\n",
        "```\n",
        "model = Deeplabv3(input_shape=(input_dim_x, input_dim_y, 3), classes=1)\n",
        "```"
      ],
      "metadata": {
        "id": "iuMgswybTBIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "d8_SlWxvUPng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Grayscale**\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1168\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1192\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1188\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1189\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1205\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.1912\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.1905\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.1893\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.1957\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.1981\n",
        "\n",
        "Best loss in Train =  0.1101\n",
        "Best loss in Validation =  0.1374\n",
        "```"
      ],
      "metadata": {
        "id": "ZcHnKS6nDVmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1AnFMpx_n_TaeY5VnL4f5ztw3uo-HmLLq\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1Ek3gu_fT0nKRsxU48MY-v2kvGIDXtSIp\"  width = 640>"
      ],
      "metadata": {
        "id": "SObDmMf_EH7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1172\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1171\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1168\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1162\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1158\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.1384\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.1382\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.1380\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.1391\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.1374\n",
        "\n",
        "Best loss in Train =  0.1017\n",
        "Best loss in Validation =  0.1102\n",
        "```"
      ],
      "metadata": {
        "id": "EgfvjWMBDSD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1Pwo0j2qVIk6RBU3JS_aCIa27lRRN4od2\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1XO3EJEbRbi_HEB7QpsuX-L-RhpE7K1Fk\"  width = 640>"
      ],
      "metadata": {
        "id": "Sy-K9hGPCUCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arrange dataset\n",
        "> Not change anything about input image(scar)"
      ],
      "metadata": {
        "id": "LAOzIhbp7gxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "labels_train = os.listdir(train_label_path)\n",
        "labels_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "label_test = os.listdir(test_label_path)\n",
        "label_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, label_train, label_val = train_test_split(inputs_train, labels_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, label_train))\n",
        "val_dataset = dict(zip(input_val, label_val))\n",
        "test_dataset = dict(zip(input_test, label_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "UdLe04Tt7MDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## ***Experimental Group***"
      ],
      "metadata": {
        "id": "sHPbY0FsOzj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 1\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Scar Image to (224, 224)"
      ],
      "metadata": {
        "id": "QcitBtU5PAHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1150\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1153\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1162\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1173\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1196\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.1589\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.1591\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.1577\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.1615\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.1598\n",
        "\n",
        "Best loss in Train =  0.1131\n",
        "Best loss in Validation =  0.1488\n",
        "```"
      ],
      "metadata": {
        "id": "0meRCPq8wdFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=17oStkRMm6qBojKLe2RBHaA52yc6a0lRg\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1HnlTAcXKoaOud-2e7pt0uo3BbzLZV1wj\"  width = 640>"
      ],
      "metadata": {
        "id": "RxXI8AHs0BFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "yltgxr4jxHZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "labels_train = os.listdir(train_label_path)\n",
        "labels_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "label_test = os.listdir(test_label_path)\n",
        "label_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, label_train, label_val = train_test_split(inputs_train, labels_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, label_train))\n",
        "val_dataset = dict(zip(input_val, label_val))\n",
        "test_dataset = dict(zip(input_test, label_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "ON4nZrW6OWjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 2\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Pad the rest part to (224, 224) based on the middle of the image"
      ],
      "metadata": {
        "id": "ZzgNKc_5QSFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1083\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1084\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1079\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1080\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1084\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.2585\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.2593\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.2617\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.2599\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.2564\n",
        "\n",
        "Best loss in Train =  0.1048\n",
        "Best loss in Validation =  0.1099\n",
        "```"
      ],
      "metadata": {
        "id": "5TRurS-tps6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1e1wr9c7kSI3RzXuEw6HVlntYZij981uB\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1opthh3TYg-VxtNPAvIbsmtGFjUZvJkq1\"  width = 640>"
      ],
      "metadata": {
        "id": "2WiLXx1IqCtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "Iz17E2XaqDrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "labels_train = os.listdir(train_label_path)\n",
        "labels_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "label_test = os.listdir(test_label_path)\n",
        "label_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, label_train, label_val = train_test_split(inputs_train, labels_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, label_train))\n",
        "val_dataset = dict(zip(input_val, label_val))\n",
        "test_dataset = dict(zip(input_test, label_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "YwmhVRrxOXMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 3\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Scar Image to (224, 224) in proportion to the maximum ratio\n",
        "3. Pad the rest part to (224, 224) in the direction of right/down "
      ],
      "metadata": {
        "id": "SJ_zsDTRPTNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1083\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1084\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1079\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1080\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1084\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.2585\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.2593\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.2617\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.2599\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.2564\n",
        "\n",
        "Best loss in Train =  0.1048\n",
        "Best loss in Validation =  0.1099\n",
        "```"
      ],
      "metadata": {
        "id": "k-aQeDdTB1pL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1r6-qdeTU1ut5iE09Smj4XSjTrdB1jPAV\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1opM4htcdcRTjrEFHXL-rlCsGkSkd0aYh\"  width = 640>"
      ],
      "metadata": {
        "id": "GfUeBkdVB49d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "AtBTf-D8CSwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "labels_train = os.listdir(train_label_path)\n",
        "labels_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "label_test = os.listdir(test_label_path)\n",
        "label_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, label_train, label_val = train_test_split(inputs_train, labels_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, label_train))\n",
        "val_dataset = dict(zip(input_val, label_val))\n",
        "test_dataset = dict(zip(input_test, label_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Calculate resized width and height\n",
        "    height = round(height * resize_scale)\n",
        "    width = round(width * resize_scale)\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Calculate resized width and height\n",
        "    height = round(height * resize_scale)\n",
        "    width = round(width * resize_scale)\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Calculate resized width and height\n",
        "    height = round(height * resize_scale)\n",
        "    width = round(width * resize_scale)\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "vuXr6qGyOXje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 4\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Scar Image to (224, 224) in proportion to the maximum ratio\n",
        "3. Pad the rest part to (224, 224) based on the middle of the image"
      ],
      "metadata": {
        "id": "Lm8__jJHPrdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1341\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1343\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1336\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1329\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1329\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.1811\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.1797\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.1756\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.1734\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.1747\n",
        "\n",
        "Best loss in Train =  0.1261\n",
        "Best loss in Validation =  0.1446\n",
        "```"
      ],
      "metadata": {
        "id": "gqrfPpWr-OaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1r6-qdeTU1ut5iE09Smj4XSjTrdB1jPAV\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1opM4htcdcRTjrEFHXL-rlCsGkSkd0aYh\"  width = 640>"
      ],
      "metadata": {
        "id": "XwvA6VmH-hHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "H-DNlgcm-dYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "labels_train = os.listdir(train_label_path)\n",
        "labels_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "label_test = os.listdir(test_label_path)\n",
        "label_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, label_train, label_val = train_test_split(inputs_train, labels_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, label_train))\n",
        "val_dataset = dict(zip(input_val, label_val))\n",
        "test_dataset = dict(zip(input_test, label_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Calculate resized width and height\n",
        "    height = round(height * resize_scale)\n",
        "    width = round(width * resize_scale)\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    if resize_criteria == 0: # criteria is width\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    # Calculate padding size\n",
        "    elif resize_criteria == 1: # criteria is heigth\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Print resize error\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Calculate resized width and height\n",
        "    height = round(height * resize_scale)\n",
        "    width = round(width * resize_scale)\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    if resize_criteria == 0: # criteria is width\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    # Calculate padding size\n",
        "    elif resize_criteria == 1: # criteria is heigth\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Print resize error\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Calculate resized width and height\n",
        "    height = round(height * resize_scale)\n",
        "    width = round(width * resize_scale)\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    if resize_criteria == 0: # criteria is width\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    # Calculate padding size\n",
        "    elif resize_criteria == 1: # criteria is heigth\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Print resize error\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "T8N95OYCOX6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 5\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Scar Image to 224 based on the smaller size(row or column), keeping the proportion\n",
        "3. Sampling by moving the kernel both on input and label, Then merge it to fit the label and input pair"
      ],
      "metadata": {
        "id": "apS4MTgAQaez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "labels_train = os.listdir(train_label_path)\n",
        "labels_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "label_test = os.listdir(test_label_path)\n",
        "label_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, label_train, label_val = train_test_split(inputs_train, labels_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, label_train))\n",
        "val_dataset = dict(zip(input_val, label_val))\n",
        "test_dataset = dict(zip(input_test, label_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w > resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Calculate resized width and height\n",
        "    height = round(height * resize_scale)\n",
        "    width = round(width * resize_scale)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w > resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Calculate resized width and height\n",
        "    height = round(height * resize_scale)\n",
        "    width = round(width * resize_scale)\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w > resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Calculate resized width and height\n",
        "    height = round(height * resize_scale)\n",
        "    width = round(width * resize_scale)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "ZOrpZ1h7OYZx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZcHnKS6nDVmW",
        "EgfvjWMBDSD0",
        "LAOzIhbp7gxx",
        "QcitBtU5PAHJ",
        "0meRCPq8wdFf",
        "ZzgNKc_5QSFx",
        "5TRurS-tps6H",
        "SJ_zsDTRPTNG",
        "Lm8__jJHPrdC"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOauSrHz2cJ58atGTHFHcpQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}