{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/image-processing/blob/feature%2FPreprocessing/Preprocessor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install**"
      ],
      "metadata": {
        "id": "rmvVB2P2aWlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZNy7tJjaUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_SoWfFhxL0-"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpg4AUPixNrD"
      },
      "outputs": [],
      "source": [
        "# Image processing\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "\n",
        "# ETC\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OHL2n1YxlH_"
      },
      "source": [
        "## Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxOqA3DpxlgC",
        "outputId": "febeeb72-ed13-4085-f5e2-e4458a97c26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqwTBfCyxm3v",
        "outputId": "a20b22a5-7d6d-4150-d7ad-b1e4116eb4d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\n",
            "total 12581\n",
            "drwx------ 2 root root     4096 Sep 14 08:50 'Case Report'\n",
            "drwx------ 2 root root     4096 Aug 16 08:53  Dataset\n",
            "drwx------ 2 root root     4096 Sep 25 16:33 '# Lagacy'\n",
            "drwx------ 2 root root     4096 Aug 17 05:49  Log\n",
            "-rw------- 1 root root  2079705 Oct  5 09:52 '[Model Tester] Down Sampling.ipynb'\n",
            "-rw------- 1 root root    97579 Oct  6 19:41  Preprocessor.ipynb\n",
            "drwx------ 2 root root     4096 Sep 14 06:04 'Raw Dataset'\n",
            "-rw------- 1 root root 10684905 Oct  6 19:38 'Surgical-Wound UNet.ipynb'\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoO0sORTxEIQ"
      },
      "source": [
        "# **Grobal variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9c_qcr4xHQR"
      },
      "outputs": [],
      "source": [
        "# Path (Absolute path in essential)\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\"\n",
        "\n",
        "RAW_DATA_PATH = \"/Raw Dataset\"\n",
        "\n",
        "WOUND_TRAIN_PATH = \"/Wound/train\"\n",
        "WOUND_TEST_PATH = \"/Wound/test\"\n",
        "CVC_INPUT_PATH = \"/CVC-clinicDB/Original\"\n",
        "CVC_GT_PATH = \"/CVC-clinicDB/Ground Truth\"\n",
        "\n",
        "DATASET_PATH = \"/Dataset\"\n",
        "\n",
        "IMAGES_PATH = '/images'\n",
        "LABELS_PATH = '/labels'\n",
        "\n",
        "# Image preprocess\n",
        "NORM_INPUT_W_SIZE = 224\n",
        "NORM_INPUT_H_SIZE = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttpnk92dc7Je"
      },
      "source": [
        "# **Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pYDBzLPc8W2"
      },
      "outputs": [],
      "source": [
        "def imshow_waitkey_enter(image):\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    input(\"Please press the Enter key to proceed\\n\")\n",
        "    output.clear()\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9mVlktdB-A"
      },
      "source": [
        "# **Make dir**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3JXzvP6dDFA"
      },
      "outputs": [],
      "source": [
        "# Create processed dataset dir\n",
        "train_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'train')\n",
        "val_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'val')\n",
        "test_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'test')\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4AWru7Aflb"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Preprocess Performace Compare Test**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "***공통사항***\n",
        "* 원본 이미지 크기 = 224 * 224\n",
        "* epoch = 100\n",
        "* batch = 8\n",
        "> UNet batch size = 4<br>\n",
        "> Wound dataset batch size = 8\n",
        "* lr = 1e-3\n",
        "* Train:Val = 7:3\n",
        "* Used model = Polar Res UNet++ (ISIC 2018 dice scroe rank no.1)\n",
        "\n",
        "<br>\n",
        "\n",
        "***주의사항***\n",
        "* 이미지의 사이즈는 정규화 되어야 한다.\n",
        "* Convolution에서 특징점을 잘 추출하기 때문에 색상영역이나, 스무딩/샤프닝 같은 필터 처리는 되려 성능저하 요소가 될 수 있다. \n",
        "\n",
        "<br>\n",
        "\n",
        "***참고사항***\n",
        "* CNN 대표 모델들의 네트워크 입력 사이즈는 224 * 224\n",
        "* 이미지의 사이즈가 큰 경우에, Overlap-Tite(down sampling) 전략으로 한 이미지를 나눠서 학습시킨다.\n",
        "\n",
        "<br>\n",
        "\n",
        "***현재 결과***\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## [***Control Group***](https://www.nature.com/articles/s41598-020-78799-w)\n",
        "> [Train code](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/train.py)\n",
        "> <br>\n",
        "> [Data generator](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/utils/io/data.py#L10)\n",
        "> <br>\n",
        "\n",
        "```\n",
        "model = Deeplabv3(input_shape=(input_dim_x, input_dim_y, 3), classes=1)\n",
        "```"
      ],
      "metadata": {
        "id": "iuMgswybTBIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance"
      ],
      "metadata": {
        "id": "d8_SlWxvUPng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train (epoch 500)**\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 500 / 500\n",
        "\n",
        "TRAIN || EPOCH 0500 | DICE LOSS 0.0389\n",
        "VALID || EPOCH 0500 | DICE LOSS 0.1028\n",
        "\n",
        "Best loss in Train (epoch 494, loss 0.0386)\n",
        "Best loss in Val (epoch 487, loss 0.0985)\n",
        "\n",
        "Model train / validate time = 10341초 / 172분 / 2시간 52분\n",
        "```"
      ],
      "metadata": {
        "id": "EgfvjWMBDSD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1vFqsvObms3O61x-QvoE_7TFXrqVi_Hl_\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1emnRmhENDMZHoMM8nYuTT9R1dmZ2Uc1E\"  width = 1080>"
      ],
      "metadata": {
        "id": "Sy-K9hGPCUCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train (epoch 200)**\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0500 | DICE LOSS 0.0829\n",
        "VALID || EPOCH 0500 | DICE LOSS 0.1117\n",
        "\n",
        "TEST || DICE_LOSS 0.1152\n",
        "\n",
        "Best loss in Train (epoch 189, loss 0.0802)\n",
        "Best loss in Val(Lastest save model) (epoch 175, loss 0.1089)\n",
        "\n",
        "Train std =  0.0812\n",
        "Val std =  0.1251\n",
        "\n",
        "Model train / validate time = 2637초 / 43분\n",
        "```"
      ],
      "metadata": {
        "id": "T-0V17Cjroy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1XDPJz-1pvqJmYXdcO79wkizCXdGfGgAt\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1pL3EgeXT9QVXxB9ZN_2a4gMsyR14HIn5\"  width = 1080>"
      ],
      "metadata": {
        "id": "bNgn-U-6rxWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Arrange dataset\n",
        "> Not change anything about input image(scar)"
      ],
      "metadata": {
        "id": "LAOzIhbp7gxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "UdLe04Tt7MDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## ***※ Effect***\n",
        "\n",
        "* The effect of dice score on resize"
      ],
      "metadata": {
        "id": "q0Cf8J2oVkKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Control group size * 2"
      ],
      "metadata": {
        "id": "T5S6oc1-YSBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess train/val\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 500 / 500\n",
        "\n",
        "TRAIN || EPOCH 0500 | DICE LOSS 0.0437\n",
        "VALID || EPOCH 0500 | DICE LOSS 0.1240\n",
        "\n",
        "TRAIN || EPOCH 0150 | DICE LOSS 0.1101\n",
        "VALID || EPOCH 0150 | DICE LOSS 0.1289\n",
        "\n",
        "Best loss in Train (epoch 496, loss 0.0398)\n",
        "Best loss in Val (epoch 231, loss 0.1158)\n",
        "\n",
        "Model train / validate time = 27510초 / 459분 / 7시간 39분\n",
        "```"
      ],
      "metadata": {
        "id": "sAY2wDssibGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=18siVBDjewA7RSI9Z1gfanxA3-zBID774\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1-acCBy0AGgXgZBvEbRqoRCe3ZRDeGR1M\"  width = 1080>"
      ],
      "metadata": {
        "id": "zPyX_rP6YgK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess train\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0958\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1738\n",
        "\n",
        "TEST || DICE_LOSS 0.1833\n",
        "\n",
        "Best loss in Train (epoch 195, loss 0.0865)\n",
        "Best loss in Val(Lastest save model) (epoch 191, loss 0.1456)\n",
        "\n",
        "Train std =  0.0953\n",
        "Val std =  0.1158\n",
        "\n",
        "Model train / validate time = 8667초 / 144분 / 2시간 24분\n",
        "```"
      ],
      "metadata": {
        "id": "OHYQBbGaif1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1jDkoInMCIiMyPyFIF-unpgyXepA-8lHV\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1I-QmQNwNY7fkychlCc-Qwr8bHRsGWg69\"  width = 1080>"
      ],
      "metadata": {
        "id": "wR6EWr_NjRoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Control group size * 1/2"
      ],
      "metadata": {
        "id": "PCm3ssvQYUu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess train/val\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 500 / 500\n",
        "\n",
        "TRAIN || EPOCH 0500 | DICE LOSS 0.0501\n",
        "VALID || EPOCH 0500 | DICE LOSS 0.1138\n",
        "\n",
        "TRAIN || EPOCH 0150 | DICE LOSS 0.1021\n",
        "VALID || EPOCH 0150 | DICE LOSS 0.1252\n",
        "\n",
        "Best loss in Train (epoch 500, loss 0.0501)\n",
        "Best loss in Val (epoch 296, loss 0.1071)\n",
        "\n",
        "Model train / validate time = 4381초 / 73분 / 1시간 13분\n",
        "```"
      ],
      "metadata": {
        "id": "Kobtv5k7khk1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1IacXpF9HLNjcEQXNob_GmRsxcOckF2CZ\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1Q6jdU-mm9kKZ0n-5HWl2oMhzw9yHtxdp\"  width = 1080>"
      ],
      "metadata": {
        "id": "3hagYsGYkkXv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess train\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0848\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.2109\n",
        "\n",
        "TEST || DICE_LOSS 0.2002\n",
        "\n",
        "Best loss in Train (epoch 181, loss 0.0798)\n",
        "Best loss in Val(Lastest save model) (epoch 199, loss 0.1691)\n",
        "\n",
        "Train std =  0.0892\n",
        "Val std =  0.1190\n",
        "\n",
        "Model train / validate time = 1308초 / 21분\n",
        "```"
      ],
      "metadata": {
        "id": "gyogzmUtkr6C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1h8-7a4fxDTLnX3AlyJ1-eB7RLm5C7uKN\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1HIYUB_dcGnv4LlVNENSgWd19-DKWoLiw\"  width = 1080>"
      ],
      "metadata": {
        "id": "b41myi5ck05k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Preprocess"
      ],
      "metadata": {
        "id": "0pwsSy_6YBUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    \"\"\"\n",
        "    # Resize (2배)\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=2.0,\n",
        "                        fy=2.0,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=2.0,\n",
        "                             fy=2.0,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "    \"\"\"\n",
        "\n",
        "    # Resize (1/2배)\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=0.5,\n",
        "                        fy=0.5,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                          (0, 0),\n",
        "                          fx=0.5,\n",
        "                          fy=0.5,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "2qzqV9X7VbtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## ***Experimental Group 1***\n",
        "\n",
        "* Resize\n",
        "* Arrange padding"
      ],
      "metadata": {
        "id": "SMMsHse91-VT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 1\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Wound Image to (224, 224)"
      ],
      "metadata": {
        "id": "QcitBtU5PAHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train/val**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 500 / 500\n",
        "\n",
        "TRAIN || EPOCH 0500 | DICE LOSS 0.0279\n",
        "VALID || EPOCH 0500 | DICE LOSS 0.1612\n",
        "\n",
        "Model train / validate time = 15063초 / 251분 / 4시간 18분\n",
        "```"
      ],
      "metadata": {
        "id": "0meRCPq8wdFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0704\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.6701\n",
        "\n",
        "TEST || DICE_LOSS 0.6256\n",
        "\n",
        "Best loss in Train (epoch 196, loss 0.0696)\n",
        "Best loss in Val(Lastest save model) (epoch 177, loss 0.3649)\n",
        "\n",
        "Train std =  0.0607\n",
        "Val std =  0.1332\n",
        "\n",
        "Model train / validate time = 4804초 / 80분 / 1시간 20분\n",
        "```"
      ],
      "metadata": {
        "id": "Tcn1R6ytNTfM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1QynGtfky5vE8NLqCyazz9KyqAqUM7HXB\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1zn6pzcK2H_9mUkFWB9J_Rip7L09uj252\"  width = 1080>"
      ],
      "metadata": {
        "id": "ITr95ZDvNoN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "yltgxr4jxHZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                          (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                          (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "ON4nZrW6OWjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 2\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Pad the rest part to (224, 224) based on the middle of the image"
      ],
      "metadata": {
        "id": "ZzgNKc_5QSFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train/val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch =  500 / 500\n",
        "\n",
        "TRAIN || EPOCH 0500 | DICE LOSS 0.0450\n",
        "VALID || EPOCH 0500 | DICE LOSS 0.1118\n",
        "\n",
        "Model train / validate time =  약 4시간\n",
        "```"
      ],
      "metadata": {
        "id": "5TRurS-tps6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0762\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1286\n",
        "\n",
        "TEST || DICE_LOSS 0.1436\n",
        "\n",
        "Best loss in Train (epoch 193, loss 0.0753)\n",
        "Best loss in Val(Lastest save model) (epoch 121, loss 0.1170)\n",
        "\n",
        "Train std =  0.0825\n",
        "Val std =  0.1220\n",
        "\n",
        "Model train / validate time = 2548초 / 42분\n",
        "```"
      ],
      "metadata": {
        "id": "GsUc8ON2NVre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1t9u0PUUKt4ulbI8_AD08qy3KL4YUCwdD\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1XBoXQU-Fi9J5gW5SatjE7wncSDXMyH61\"  width = 1080>"
      ],
      "metadata": {
        "id": "2DBHJi3cNuTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "Iz17E2XaqDrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "YwmhVRrxOXMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 3\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Wound Image to (224, 224) in proportion to the maximum ratio\n",
        "3. Pad the rest part to (224, 224) in the direction of right/down "
      ],
      "metadata": {
        "id": "SJ_zsDTRPTNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train/val**\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 500 / 500\n",
        "\n",
        "TRAIN || EPOCH 0500 | DICE LOSS 0.0847\n",
        "VALID || EPOCH 0500 | DICE LOSS 0.1836\n",
        "\n",
        "Best loss in Train =  0.0324\n",
        "Best loss in Validation = 0.1328\n",
        "\n",
        "Model train / validate time = 12223초 / 203분 / 3시간 28분\n",
        "```"
      ],
      "metadata": {
        "id": "k-aQeDdTB1pL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0861\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1815\n",
        "\n",
        "TEST || DICE_LOSS 0.1817\n",
        "\n",
        "Best loss in Train (epoch 200, loss 0.0861)\n",
        "Best loss in Val(Lastest save model) (epoch 138, loss 0.1605)\n",
        "\n",
        "Train std =  0.0628\n",
        "Val std =  0.0928\n",
        "\n",
        "Model train / validate time = 3908초 / 65분 / 1시간 5분\n",
        "```"
      ],
      "metadata": {
        "id": "bf2SdSHdNX3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1ODSybzXGQhyIqd8GtqAXtvKHcdXZDUaq\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1AiK5XYVcgjdZrtGo2S8D5t2m-NSfyJyP\"  width = 1080>"
      ],
      "metadata": {
        "id": "oxN5JqAENwHj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "AtBTf-D8CSwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "vuXr6qGyOXje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 4\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Wound Image to (224, 224) in proportion to the maximum ratio\n",
        "3. Pad the rest part to (224, 224) based on the middle of the image"
      ],
      "metadata": {
        "id": "Lm8__jJHPrdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train/val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 500 / 500\n",
        "\n",
        "TRAIN || EPOCH 0500 | DICE LOSS 0.0291\n",
        "VALID || EPOCH 0500 | DICE LOSS 0.1664\n",
        "\n",
        "Best loss in Train =  0.0279\n",
        "Best loss in Validation = 0.1341\n",
        "\n",
        "Model train / validate time = 12279초 / 204분 / 3시 24분\n",
        "```"
      ],
      "metadata": {
        "id": "gqrfPpWr-OaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0825\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1633\n",
        "\n",
        "TEST || DICE_LOSS 0.1960\n",
        "\n",
        "Best loss in Train (epoch 200, loss 0.0825)\n",
        "Best loss in Val(Lastest save model) (epoch 200, loss 0.1633)\n",
        "\n",
        "Train std =  0.0736\n",
        "Val std =  0.0903\n",
        "\n",
        "Model train / validate time = 4426초 / 73분 / 1시간 13분\n",
        "```"
      ],
      "metadata": {
        "id": "OMwCGG5zNaAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1JhvW3htgLy61eObwmPkiz-xjP7f3lKAO\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1eRvyzGoPKeX9Zby4AGoukJQ9WkmUxwk6\"  width = 1080>"
      ],
      "metadata": {
        "id": "QzM05XJdNx6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "H-DNlgcm-dYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    if resize_criteria == 0: # criteria is width\n",
        "        pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    # Calculate padding size\n",
        "    elif resize_criteria == 1: # criteria is heigth\n",
        "        pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Print resize error\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    if resize_criteria == 0: # criteria is width\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    # Calculate padding size\n",
        "    elif resize_criteria == 1: # criteria is heigth\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Print resize error\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    if resize_criteria == 0: # criteria is width\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    # Calculate padding size\n",
        "    elif resize_criteria == 1: # criteria is heigth\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Print resize error\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "T8N95OYCOX6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 5\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Wound Image to (204, 204) in proportion to the maximum ratio\n",
        "3. Pad the rest part to (224, 224) based on the middle of the image"
      ],
      "metadata": {
        "id": "0azgBDw_3R-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train/val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch =  / 500\n",
        "\n",
        "TRAIN || EPOCH 0484 | DICE LOSS 0.0325\n",
        "VALID || EPOCH 0484 | DICE LOSS 0.1715\n",
        "\n",
        "Best loss in Train = 0.0287\n",
        "Best loss in Validation = 0.1366\n",
        "\n",
        "Model train / validate time = 12514초 / 209분 / 3시간 29분\n",
        "```"
      ],
      "metadata": {
        "id": "QB42zXzbAnRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0866\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1915\n",
        "\n",
        "TEST || DICE_LOSS 0.1949\n",
        "\n",
        "Best loss in Train (epoch 192, loss 0.0862)\n",
        "Best loss in Val(Lastest save model) (epoch 183, loss 0.1619)\n",
        "\n",
        "Train std =  0.0666\n",
        "Val std =  0.0729\n",
        "\n",
        "Model train / validate time = 4144초 / 69분 / 1시간 9분\n",
        "```"
      ],
      "metadata": {
        "id": "d4v6mw5WNcJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1zEx2ATMhdGFUZDq9AQnTRRix4iBEnubR\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1gLwRx5cW4eDNPtwQIyAxLn1BantXJQFr\"  width = 1080>"
      ],
      "metadata": {
        "id": "31r393lNN0Kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "n_Ijqr-cAsre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (204, 204) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = (NORM_INPUT_W_SIZE - 20) / width\n",
        "    resize_scale_h = (NORM_INPUT_H_SIZE - 20) / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "    pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "        \n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "\n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (204, 204) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = (NORM_INPUT_W_SIZE - 20) / width\n",
        "    resize_scale_h = (NORM_INPUT_H_SIZE - 20) / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "    pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "        \n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "\n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (204, 204) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = (NORM_INPUT_W_SIZE - 20) / width\n",
        "    resize_scale_h = (NORM_INPUT_H_SIZE - 20) / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "    pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "        \n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "\n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "jo09GwRG3gMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Case 5-1"
      ],
      "metadata": {
        "id": "CknmmHQXuSOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Preprocess"
      ],
      "metadata": {
        "id": "Z3pzK8UUulrJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (204, 204) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = (NORM_INPUT_W_SIZE - 20) / width\n",
        "    resize_scale_h = (NORM_INPUT_H_SIZE - 20) / height\n",
        "    resize_scale_w = resize_scale_w - ((resize_scale_w - 1) / 2)\n",
        "    resize_scale_h = resize_scale_h - ((resize_scale_h - 1) / 2)\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "    pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "        \n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "\n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (204, 204) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = (NORM_INPUT_W_SIZE - 20) / width\n",
        "    resize_scale_h = (NORM_INPUT_H_SIZE - 20) / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "    pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "        \n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "\n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (204, 204) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = (NORM_INPUT_W_SIZE - 20) / width\n",
        "    resize_scale_h = (NORM_INPUT_H_SIZE - 20) / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (0, 0),\n",
        "                          fx=resize_scale,\n",
        "                          fy=resize_scale,\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    pad_height = round((NORM_INPUT_H_SIZE - height) / 2)\n",
        "    pad_width = round((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "        \n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "\n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "OjYrdWLPuauU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Control + Case 1"
      ],
      "metadata": {
        "id": "FBHnFS1_R8DM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0847\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1286\n",
        "\n",
        "TEST || DICE_LOSS 0.1314\n",
        "\n",
        "Best loss in Train (epoch 199, loss 0.0831)\n",
        "Best loss in Val(Lastest save model) (epoch 192, loss 0.1200)\n",
        "\n",
        "Train std =  0.0600\n",
        "Val std =  0.0811\n",
        "\n",
        "Model train / validate time = 6636초 / 110분 / 1시간 50분\n",
        "```"
      ],
      "metadata": {
        "id": "hENTle0LSAnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=17aoG7A8MaDnwt65VaH9PH8IqEJxU9okV\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=115QY-tcxAgzN1sXwD8-G6t-N3QgcXQLW\"  width = 1080>"
      ],
      "metadata": {
        "id": "HsiibWJfSDSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Control + Case 2"
      ],
      "metadata": {
        "id": "5wlUatKVYfyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0662\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1055\n",
        "\n",
        "TEST || DICE_LOSS 0.1139\n",
        "\n",
        "Best loss in Train (epoch 199, loss 0.0606)\n",
        "Best loss in Val(Lastest save model) (epoch 199, loss 0.1005)\n",
        "\n",
        "Train std =  0.0748\n",
        "Val std =  0.0658\n",
        "\n",
        "Model train / validate time = 4794초 / 80분 / 1시간 20분\n",
        "```"
      ],
      "metadata": {
        "id": "ENPKCbFRYphq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1qZO2fPVKKrbkKCXx8JNcK8jpSWN8YhNC\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1Bbv_rO__mheOr3mmVROM6jKXJAQgkdiE\"  width = 1080>"
      ],
      "metadata": {
        "id": "LkC5Jvv4ZVet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Control + Case 3"
      ],
      "metadata": {
        "id": "mPmDbU-TYg9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0971\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1235\n",
        "\n",
        "TEST || DICE_LOSS 0.1206\n",
        "\n",
        "Best loss in Train (epoch 195, loss 0.0935)\n",
        "Best loss in Val(Lastest save model) (epoch 182, loss 0.1132)\n",
        "\n",
        "Train std =  0.0587\n",
        "Val std =  0.0649\n",
        "\n",
        "Model train / validate time = 6376초 / 106분 / 1시간 46분\n",
        "```"
      ],
      "metadata": {
        "id": "QO1X-PsTYqN8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1D8UPyD0WCKtLrLDJOkc7p1KA9lMNKNdN\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1GhjoeuEOTmtHUl4S34-5oumpEJzu8vcu\"  width = 1080>"
      ],
      "metadata": {
        "id": "ZM4pu3lMZYoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Control + Case 4"
      ],
      "metadata": {
        "id": "c0VGkI-AYhoK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0886\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1184\n",
        "\n",
        "TEST || DICE_LOSS 0.1115\n",
        "\n",
        "Best loss in Train (epoch 194, loss 0.0885)\n",
        "Best loss in Val(Lastest save model) (epoch 194, loss 0.1137)\n",
        "\n",
        "Train std =  0.0630\n",
        "Val std =  0.1175\n",
        "\n",
        "Model train / validate time = 6432초 / 107분 / 1시간 47분\n",
        "```"
      ],
      "metadata": {
        "id": "eJ6uvHrhYrFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1nlvANqS6pZjo0Fx4ZqUpbwV2MyLL4NiC\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1-V452CopNSnZtmZepng2bVF1Hihk67EJ\"  width = 1080>"
      ],
      "metadata": {
        "id": "5ahI26UIZZuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Control + Case 5"
      ],
      "metadata": {
        "id": "vBv3To5VYiQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0851\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1308\n",
        "\n",
        "TEST || DICE_LOSS 0.1284\n",
        "\n",
        "Best loss in Train (epoch 199, loss 0.0832)\n",
        "Best loss in Val(Lastest save model) (epoch 175, loss 0.1110)\n",
        "\n",
        "Train std =  0.0665\n",
        "Val std =  0.0808\n",
        "\n",
        "Model train / validate time = 6150초 / 102분 / 1시간 42분\n",
        "```"
      ],
      "metadata": {
        "id": "GQh0FIYwYrsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1AMa1fPkom1prP7Gark3K88gAWuTPELen\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1O8Wucz90xvbYb_aGArF6JbKBaU5m-xuP\"  width = 1080>"
      ],
      "metadata": {
        "id": "xhM-DRmLZa7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "## ***Experimental Group 2***\n",
        "* Experimental Group 2 + Threshold resized ground-truth"
      ],
      "metadata": {
        "id": "GrDT0fF-2ShR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Control + Case 1, 2, 3, 4"
      ],
      "metadata": {
        "id": "tVRRbGsEgjc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0499\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1235\n",
        "\n",
        "TEST || DICE_LOSS 0.1203\n",
        "\n",
        "Best loss in Train (epoch 200, loss 0.0499)\n",
        "Best loss in Val(Lastest save model) (epoch 152, loss 0.1057)\n",
        "\n",
        "Train std =  0.0558\n",
        "Val std =  0.0454\n",
        "\n",
        "Model train / validate time = 17151초 / 285분 / 4시간 45분\n",
        "```"
      ],
      "metadata": {
        "id": "9z311unHgwnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1UTyvzPzATpoTwb3gmcEgbo_b2dt5VjeY\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1nFKJA1IoP00gfDTMaJ1nJZ0sKQKUpcIh\"  width = 1080>"
      ],
      "metadata": {
        "id": "_H67Ekkenk7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Control + Case 1, 2, 3, 5"
      ],
      "metadata": {
        "id": "thmu3VIkYjfy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Preprocess train, Raw val**\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "TRAIN || EPOCH 0200 | DICE LOSS 0.0463\n",
        "VALID || EPOCH 0200 | DICE LOSS 0.1074\n",
        "\n",
        "TEST || DICE_LOSS 0.1142\n",
        "\n",
        "Best loss in Train (epoch 200, loss 0.0463)\n",
        "Best loss in Val(Lastest save model) (epoch 190, loss 0.1053)\n",
        "\n",
        "Train std =  0.0578\n",
        "Val std =  0.0414\n",
        "\n",
        "Model train / validate time = 15772초 / 262분 / 4시간 22분\n",
        "```"
      ],
      "metadata": {
        "id": "GzcyDUGBZd9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1mX_PT3reGzypp4Ua69XNwq63a9csl2Dd\"  width = 1080>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1XVcXFQYVj-ZaLs6MfXDAIH0qcuR1ohK5\"  width = 1080>"
      ],
      "metadata": {
        "id": "cFQPLIdXZcEM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iuMgswybTBIn",
        "d8_SlWxvUPng",
        "EgfvjWMBDSD0",
        "T-0V17Cjroy8",
        "LAOzIhbp7gxx",
        "q0Cf8J2oVkKF",
        "T5S6oc1-YSBl",
        "sAY2wDssibGN",
        "OHYQBbGaif1O",
        "PCm3ssvQYUu8",
        "Kobtv5k7khk1",
        "gyogzmUtkr6C",
        "0pwsSy_6YBUF",
        "QcitBtU5PAHJ",
        "Tcn1R6ytNTfM",
        "yltgxr4jxHZR",
        "ZzgNKc_5QSFx",
        "GsUc8ON2NVre",
        "Iz17E2XaqDrv",
        "SJ_zsDTRPTNG",
        "bf2SdSHdNX3a",
        "AtBTf-D8CSwi",
        "Lm8__jJHPrdC",
        "OMwCGG5zNaAA",
        "H-DNlgcm-dYU",
        "d4v6mw5WNcJS",
        "n_Ijqr-cAsre",
        "CknmmHQXuSOW",
        "FBHnFS1_R8DM",
        "hENTle0LSAnd",
        "5wlUatKVYfyK",
        "ENPKCbFRYphq",
        "mPmDbU-TYg9F",
        "QO1X-PsTYqN8",
        "c0VGkI-AYhoK",
        "eJ6uvHrhYrFo",
        "vBv3To5VYiQ6",
        "GQh0FIYwYrsK",
        "GrDT0fF-2ShR",
        "tVRRbGsEgjc_",
        "thmu3VIkYjfy",
        "GzcyDUGBZd9F"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMmKgp2MOeeU0b7PS0/0UOI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}