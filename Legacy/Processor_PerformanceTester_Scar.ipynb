{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/image-processing/blob/feature%2FUnet-scar/Processor_PerformanceTester_Scar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install**"
      ],
      "metadata": {
        "id": "rmvVB2P2aWlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZNy7tJjaUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_SoWfFhxL0-"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xpg4AUPixNrD"
      },
      "outputs": [],
      "source": [
        "# Image processing\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "\n",
        "# ETC\n",
        "import os\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OHL2n1YxlH_"
      },
      "source": [
        "## Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxOqA3DpxlgC",
        "outputId": "2ce09714-78ca-4750-86d3-a1e5e3de7bff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqwTBfCyxm3v",
        "outputId": "eec9a859-24e9-4a0b-f9cc-b8118d4f7108"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Models/GAN_Scar\n",
            "total 534\n",
            "drwx------ 2 root root   4096 Aug 16 08:53  Dataset\n",
            "-rw------- 1 root root  22891 Sep  1 12:04  Image_segmentation-Scar.ipynb\n",
            "drwx------ 2 root root   4096 Aug 17 05:49  Log\n",
            "-rw------- 1 root root 120592 Sep 13 08:26  Processor_PerformanceTester-Scar.ipynb\n",
            "drwx------ 2 root root   4096 Aug 16 08:39  Raw_Dataset\n",
            "-rw------- 1 root root  16167 Sep  1 12:13  RawDataset_Processor-Scar.ipynb\n",
            "drwx------ 2 root root   4096 Aug 23 14:47  result\n",
            "-rw------- 1 root root  39995 Aug 15 11:40 'UNet architecture.PNG'\n",
            "-rw------- 1 root root 329418 Sep 12 11:32  Unet-Scar.ipynb\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Models/GAN_Scar\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoO0sORTxEIQ"
      },
      "source": [
        "# **Grobal variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z9c_qcr4xHQR"
      },
      "outputs": [],
      "source": [
        "# Path\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/Models/GAN_Scar\"\n",
        "\n",
        "RAW_TRAIN_SET_PATH = \"/Raw_Dataset/train\"\n",
        "RAW_TEST_SET_PATH = \"/Raw_Dataset/test\"\n",
        "\n",
        "DATASET_PATH = \"/Dataset\"\n",
        "\n",
        "IMAGES_PATH = '/images'\n",
        "LABELS_PATH = '/labels'\n",
        "\n",
        "# Image preprocess\n",
        "NORM_INPUT_W_SIZE = 512\n",
        "NORM_INPUT_H_SIZE = 384"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttpnk92dc7Je"
      },
      "source": [
        "# **Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8pYDBzLPc8W2"
      },
      "outputs": [],
      "source": [
        "def imshow_waitkey_enter(image):\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    input(\"Please press the Enter key to proceed\\n\")\n",
        "    output.clear()\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9mVlktdB-A"
      },
      "source": [
        "# **Make dir**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c3JXzvP6dDFA"
      },
      "outputs": [],
      "source": [
        "# Create processed dataset dir\n",
        "train_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'train')\n",
        "val_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'val')\n",
        "test_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'test')\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4AWru7Aflb"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# ***데이터셋 학습 비교 실험***\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "***공통사항***\n",
        "* 원본 이미지 크기 = 244 * 244\n",
        "* epoch = 40\n",
        "* batch = 8\n",
        "> UNet batch size = 4 <br>\n",
        "> Wound dataset batch size = 8\n",
        "* lr = 1e-3\n",
        "* Train:Val = 8:2\n",
        "* Used model = Polar Res UNet++ (ISIC 2018 dice scroe rank no.1)\n",
        "\n",
        "<br>\n",
        "\n",
        "***주의사항***\n",
        "* 이미지의 사이즈는 정규화 되어야 한다.\n",
        "* 실험군(Grayscale)과 실험군(Color)의 모델 차이는 입력 채널 수 밖에 없다.\n",
        "\n",
        "<br>\n",
        "\n",
        "***참고사항***\n",
        "* CNN 대표 모델들의 네트워크 입력 사이즈는 224 * 224\n",
        "* 이미지의 사이즈가 큰 경우에, Overlap-Tite(down sampling) 전략으로 한 이미지를 나눠서 학습시킨다.\n",
        "* Polar Res UNet++ 의 input/output 사이즈는 [(384*512) == (y, x)](https://github.com/marinbenc/medical-polar-training/blob/main/datasets/lesion/make_dataset.py#L62)\n",
        "> Dice score = 0.925 (Dice loss = 0.075)\n",
        "\n",
        "<br>\n",
        "\n",
        "***현재 결과***\n",
        "* Resize 하면 loss가 높아져서 안 좋다.\n",
        "> Resize가 아닌 Bordering을 통해 Size를 조정해야한다.\n",
        "* Color나 Grayscale이나 성능차이가 안 난다.\n",
        "> Grayscale이 학습이 빠르므로 Grayscale로 학습한다.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## [***대조군***](https://www.nature.com/articles/s41598-020-78799-w)\n",
        "> [Train code](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/train.py)\n",
        "> <br>\n",
        "> [Data generator](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/utils/io/data.py#L10)\n",
        "> <br>\n",
        "> <br>\n",
        "> Raw dataset에 대한 전처리 없이, load 후 model에 들어가기 전에 Normalize\n",
        "> <br>\n",
        "> * 현재까지 대조군 성능을 넘은 실험군이 없다.\n",
        "\n",
        "```\n",
        "model = Deeplabv3(input_shape=(input_dim_x, input_dim_y, 3), classes=1)\n",
        "```"
      ],
      "metadata": {
        "id": "iuMgswybTBIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance\n",
        "\n",
        "<br>\n",
        "\n",
        "**Gray scale**\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.1887\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.1890\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.1885\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.1872\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.1864\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.1605\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.1673\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.1699\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.1710\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.1736\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "**Color**\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.1855\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.1848\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.1838\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.1835\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.1824\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.1781\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.1831\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.1798\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.1789\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.1865\n",
        "\n",
        "Best loss in Train =  0.1824\n",
        "Best loss in Validation =  0.1812\n",
        "```"
      ],
      "metadata": {
        "id": "d8_SlWxvUPng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arrange dataset\n",
        "> Not change anything about input image(scar)"
      ],
      "metadata": {
        "id": "LAOzIhbp7gxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 8:2\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "UdLe04Tt7MDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "oFWrZfRe7zpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## ***실험군 (Grayscale)***"
      ],
      "metadata": {
        "id": "Y4_rZUZrTdSr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZUKRe7MccGb"
      },
      "source": [
        "### 1\n",
        "\n",
        "*적용사항*\n",
        "1. Lab space의 l, a 채널 CLAHE Contrast 조정\n",
        "2. BGR의 Green channel을 CLAHE Contrast 조정 후 input으로 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.2240\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.2236\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.2238\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.2234\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.2225\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.2402\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.2370\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.2446\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.2444\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.2418\n",
        "```"
      ],
      "metadata": {
        "id": "AZ5JiTZ1-Sp3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGnC5SL1dPQA"
      },
      "source": [
        "#### Process dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train"
      ],
      "metadata": {
        "id": "gL9q8KvhsZtD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yljPDLtm0zuo"
      },
      "outputs": [],
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 8:2\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU5G6MgG25A0"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIU5Cv4f2wGo"
      },
      "outputs": [],
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1-1)\n",
        "\n",
        "*변경된 적용사항*\n",
        "1. Black boundary 제거\n",
        "2. Lab space의 l, a 채널 CLAHE Contrast 조정\n",
        "3. BGR의 Green channel을 CLAHE Contrast 조정\n",
        "4. Right/Bottom으로 bordering to size (384, 512) == (y, x)"
      ],
      "metadata": {
        "id": "yEYMmQWNAmdK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Performance\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 384, 512])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.2337\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.2344\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.2339\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.2340\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.2340\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.2312\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.2324\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.2281\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.2353\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.2403\n",
        "```"
      ],
      "metadata": {
        "id": "KueS-p8IBOua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Process dataset"
      ],
      "metadata": {
        "id": "gLWJZjY_BBP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Train"
      ],
      "metadata": {
        "id": "PbfcWUkiBED0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 8:2\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "# =======================================================================\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Pad image\n",
        "    pad_right = int((NORM_INPUT_W_SIZE - width))\n",
        "    pad_bottom = int((NORM_INPUT_H_SIZE - height))\n",
        "\n",
        "    green_image = cv2.copyMakeBorder(green_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "# =======================================================================\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "# =======================================================================\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Pad image\n",
        "    pad_right = int((NORM_INPUT_W_SIZE - width))\n",
        "    pad_bottom = int((NORM_INPUT_H_SIZE - height))\n",
        "\n",
        "    green_image = cv2.copyMakeBorder(green_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "# =======================================================================\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "JJd7EGcJBGpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Test"
      ],
      "metadata": {
        "id": "dHbG40z_BDvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "# =======================================================================\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Pad image\n",
        "    pad_right = int((NORM_INPUT_W_SIZE - width))\n",
        "    pad_bottom = int((NORM_INPUT_H_SIZE - height))\n",
        "\n",
        "    green_image = cv2.copyMakeBorder(green_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "# =======================================================================\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "spmJv-peBG8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhgq7zplcjoh"
      },
      "source": [
        "### 2\n",
        "\n",
        "*적용사항*\n",
        "1. 불필요 Black boundary 제거\n",
        "2. Lab space의 l, a 채널 CLAHE Contrast 조정\n",
        "3. BGR의 Green channel을 CLAHE Contrast 조정\n",
        "4. Resize input/output to 384*512 (y, x)\n",
        "> UNet 아키텍쳐 입력 이미지 사이즈"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 384, 512])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.2960\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.2947\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.2943\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.2956\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.2950\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.2981\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.2936\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.2851\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.2860\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.2872\n",
        "```"
      ],
      "metadata": {
        "id": "bUaRzvyV-V-D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIYSvyIfg37Q"
      },
      "source": [
        "#### Process dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train"
      ],
      "metadata": {
        "id": "MIqYMuSCsftk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecWAX5SGg4Hw"
      },
      "outputs": [],
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 8:2\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    if width > height: height = width\n",
        "    else: width = height\n",
        "# =======================================================================\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Resize image\n",
        "    green_image = cv2.resize(green_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "# =======================================================================\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    if width > height: height = width\n",
        "    else: width = height\n",
        "# =======================================================================\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Resize image\n",
        "    green_image = cv2.resize(green_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "# =======================================================================\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9izC65bg7vV"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BnUptGVg72g"
      },
      "outputs": [],
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    if width > height: height = width\n",
        "    else: width = height\n",
        "# =======================================================================\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Resize image\n",
        "    green_image = cv2.resize(green_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "# =======================================================================\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWxTg5BSop6e"
      },
      "source": [
        "### 3 (성능 제일 좋음)\n",
        "\n",
        "*적용사항*\n",
        "1. Black boundary 모두 제거\n",
        "2. Lab space의 l, a 채널 CLAHE Contrast 조정\n",
        "3. BGR의 Green channel을 CLAHE Contrast 조정\n",
        "4. Bordering(cv2.copymakeborder CONSTANT) input/output to 384*512 (y, x)\n",
        "> UNet 아키텍쳐 입력 이미지 사이즈"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Performance\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 384, 512])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.2293\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.2289\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.2284\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.2279\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.2279\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.2322\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.2458\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.2446\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.2419\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.2499\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "1dFrSvaE-aBx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJnrN--ao5xc"
      },
      "source": [
        "#### Process dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train"
      ],
      "metadata": {
        "id": "ox2kye1-smhP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBf58SJVo5SY"
      },
      "outputs": [],
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 8:2\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    green_image = cv2.copyMakeBorder(green_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "# =======================================================================\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    green_image = cv2.copyMakeBorder(green_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "# =======================================================================\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl46mYQto6Dr"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGFmaB8Zo6r5"
      },
      "outputs": [],
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    green_image = cv2.copyMakeBorder(green_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "# =======================================================================\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3-1)\n",
        "\n",
        "3. BGR의 Green channel을 CLAHE Contrast 조정\n",
        "> 변경) Blue constrast down, Red/Green contrast up"
      ],
      "metadata": {
        "id": "L6R_SgbCtWFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Performance\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 384, 512])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.2519\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.2507\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.2511\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.2521\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.2513\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.3144\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.3115\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.3074\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.3134\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.3137\n",
        "\n",
        "Best loss in Train =  0.2499\n",
        "Best loss in Validation =  0.2536\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "jjU9wlcdtZEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 8:2\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "# ============================ Modified code ============================\n",
        "    enhanced_lab = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_bgr = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_bgr)\n",
        "\n",
        "    b_alpha = -0.5\n",
        "    g_alpha = 2.5\n",
        "    r_alpha = 1.5\n",
        "\n",
        "    blue_image = np.clip((1 + b_alpha)*blue_image - (128 * b_alpha), 0, 255).astype(np.uint8)\n",
        "    green_image = np.clip((1 + g_alpha)*green_image - (128 * g_alpha), 0, 255).astype(np.uint8)\n",
        "    red_image = np.clip((1 + r_alpha)*red_image - (128 * r_alpha), 0, 255).astype(np.uint8)\n",
        "\n",
        "    enhanced_bgr = cv2.merge((blue_image, green_image, red_image))\n",
        "    gray_input = cv2.cvtColor(enhanced_bgr, cv2.COLOR_BGR2GRAY)\n",
        "# =======================================================================\n",
        "\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    gray_input = cv2.copyMakeBorder(gray_input,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), gray_input)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "# ============================ Modified code ============================\n",
        "    enhanced_lab = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_bgr = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_bgr)\n",
        "\n",
        "    b_alpha = -0.5\n",
        "    g_alpha = 2.5\n",
        "    r_alpha = 1.5\n",
        "\n",
        "    blue_image = np.clip((1 + b_alpha)*blue_image - (128 * b_alpha), 0, 255).astype(np.uint8)\n",
        "    green_image = np.clip((1 + g_alpha)*green_image - (128 * g_alpha), 0, 255).astype(np.uint8)\n",
        "    red_image = np.clip((1 + r_alpha)*red_image - (128 * r_alpha), 0, 255).astype(np.uint8)\n",
        "\n",
        "    enhanced_bgr = cv2.merge((blue_image, green_image, red_image))\n",
        "    gray_input = cv2.cvtColor(enhanced_bgr, cv2.COLOR_BGR2GRAY)\n",
        "# =======================================================================\n",
        "\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    gray_input = cv2.copyMakeBorder(gray_input,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), gray_input)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "9LkCDwUEteYo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4\n",
        "\n",
        "*적용사항*\n",
        "1. Black boundary 모두 제거\n",
        "2. Lab space의 l, a 채널 CLAHE Contrast 조정\n",
        "3. BGR의 Green channel을 CLAHE Contrast 조정\n",
        "4. Resize input/label width to 384 or height to 512 (비율 유지)\n",
        "5. Bordering(cv2.copymakeborder CONSTANT) input/output to 384*512 (y, x)\n",
        "> UNet 아키텍쳐 입력 이미지 사이즈"
      ],
      "metadata": {
        "id": "1Yxo1r0o1gQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 384, 512])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.2895\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.2880\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.2888\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.2885\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.2902\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.2928\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.2864\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.2852\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.2823\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.2844\n",
        "```"
      ],
      "metadata": {
        "id": "LmRR68162Q_5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Process dataset"
      ],
      "metadata": {
        "id": "BJhV03IK2RTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train"
      ],
      "metadata": {
        "id": "jBEewoRYss9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 8:2\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Resize images\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    green_image = cv2.resize(green_image,\n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    width = round(width * resize_scale)\n",
        "    height = round(height * resize_scale)\n",
        "# =======================================================================\n",
        "\n",
        "# ============================ Modified code ============================\n",
        "    # Pad image\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    if resize_criteria == 0:\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    elif resize_criteria == 1:\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    green_image = cv2.copyMakeBorder(green_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "# =======================================================================\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    \n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Resize images\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    green_image = cv2.resize(green_image,\n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    width = round(width * resize_scale)\n",
        "    height = round(height * resize_scale)\n",
        "# =======================================================================\n",
        "\n",
        "# ============================ Modified code ============================\n",
        "    # Pad image\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    if resize_criteria == 0:\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    elif resize_criteria == 1:\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    green_image = cv2.copyMakeBorder(green_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "# =======================================================================\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "FLbx55hB2Rrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test"
      ],
      "metadata": {
        "id": "tvhoc1by2R82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "    \n",
        "# ============================== Added code ==============================\n",
        "    # Resize images\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    green_image = cv2.resize(green_image,\n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    width = round(width * resize_scale)\n",
        "    height = round(height * resize_scale)\n",
        "# =======================================================================\n",
        "\n",
        "# ============================ Modified code ============================\n",
        "    # Pad image\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    if resize_criteria == 0:\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    elif resize_criteria == 1:\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    green_image = cv2.copyMakeBorder(green_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "# =======================================================================\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "PuYwFWWn2SRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5\n",
        "\n",
        "*적용사항*\n",
        "1. Black boundary 모두 제거\n",
        "2. Lab space의 l, a 채널 CLAHE Contrast 조정\n",
        "3. K-Means(k=3)를 이용한 이미지 분류\n",
        "4. Resize input/label width to 384 or height to 512 (비율 유지)\n",
        "5. Bordering(cv2.copymakeborder CONSTANT) input/output to 384*512 (y, x)\n",
        "> UNet 아키텍쳐 입력 이미지 사이즈"
      ],
      "metadata": {
        "id": "LqgHSjqj-dBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 384, 512])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.3189\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.3178\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.3177\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.3207\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.3198\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.3028\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.2980\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.3053\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.3081\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.3027\n",
        "```"
      ],
      "metadata": {
        "id": "FD1t6uTb_73Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Process dataset"
      ],
      "metadata": {
        "id": "R8DC7EAS_A4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train"
      ],
      "metadata": {
        "id": "K7AtZAoesxyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 8:2\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    \n",
        "# ============================== Added code ==============================\n",
        "    # Clustering use K-means\n",
        "    cluster_data = enhanced_image.reshape((-1, 3)).astype(np.float32)\n",
        "    k = 3\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS|cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0) # 최대 10번 반복하고 1픽셀 이하로 움직이면 종료\n",
        "    ret, c_label, center = cv2.kmeans(cluster_data, \n",
        "                                    k, \n",
        "                                    None, \n",
        "                                    criteria,\n",
        "                                    10,\n",
        "                                    cv2.KMEANS_RANDOM_CENTERS)\n",
        "    \n",
        "    center = np.uint8(center)\n",
        "    kmeans_image = center[c_label.flatten()]\n",
        "    kmeans_image = kmeans_image.reshape((enhanced_image.shape))\n",
        "    kmeans_image = cv2.cvtColor(kmeans_image, cv2.COLOR_BGR2GRAY)\n",
        "# =======================================================================\n",
        "\n",
        "# ============================ Modified code ============================\n",
        "    # Resize images\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    kmeans_image = cv2.resize(kmeans_image,\n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    width = round(width * resize_scale)\n",
        "    height = round(height * resize_scale)\n",
        "# =======================================================================\n",
        "\n",
        "    # Pad image\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    if resize_criteria == 0:\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    elif resize_criteria == 1:\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    kmeans_image = cv2.copyMakeBorder(kmeans_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), kmeans_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    \n",
        "# ============================== Added code ==============================\n",
        "    # Clustering use K-means\n",
        "    cluster_data = enhanced_image.reshape((-1, 3)).astype(np.float32)\n",
        "    k = 3\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS|cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0) # 최대 10번 반복하고 1픽셀 이하로 움직이면 종료\n",
        "    ret, c_label, center = cv2.kmeans(cluster_data, \n",
        "                                    k, \n",
        "                                    None, \n",
        "                                    criteria,\n",
        "                                    10,\n",
        "                                    cv2.KMEANS_RANDOM_CENTERS)\n",
        "    \n",
        "    center = np.uint8(center)\n",
        "    kmeans_image = center[c_label.flatten()]\n",
        "    kmeans_image = kmeans_image.reshape((enhanced_image.shape))\n",
        "    kmeans_image = cv2.cvtColor(kmeans_image, cv2.COLOR_BGR2GRAY)\n",
        "# =======================================================================\n",
        "\n",
        "# ============================ Modified code ============================\n",
        "    # Resize images\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    kmeans_image = cv2.resize(kmeans_image,\n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    width = round(width * resize_scale)\n",
        "    height = round(height * resize_scale)\n",
        "# =======================================================================\n",
        "\n",
        "    # Pad image\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    if resize_criteria == 0:\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    elif resize_criteria == 1:\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    kmeans_image = cv2.copyMakeBorder(kmeans_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{idx:03d}.png'), kmeans_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "Zgg9Ps9g_Bm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test"
      ],
      "metadata": {
        "id": "BLmbVKdb_B0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    \n",
        "# ============================== Added code ==============================\n",
        "    # Clustering use K-means\n",
        "    cluster_data = enhanced_image.reshape((-1, 3)).astype(np.float32)\n",
        "    k = 3\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS|cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0) # 최대 10번 반복하고 1픽셀 이하로 움직이면 종료\n",
        "    ret, c_label, center = cv2.kmeans(cluster_data, \n",
        "                                    k, \n",
        "                                    None, \n",
        "                                    criteria,\n",
        "                                    10,\n",
        "                                    cv2.KMEANS_RANDOM_CENTERS)\n",
        "    \n",
        "    center = np.uint8(center)\n",
        "    kmeans_image = center[c_label.flatten()]\n",
        "    kmeans_image = kmeans_image.reshape((enhanced_image.shape))\n",
        "    kmeans_image = cv2.cvtColor(kmeans_image, cv2.COLOR_BGR2GRAY)\n",
        "# =======================================================================\n",
        "\n",
        "# ============================ Modified code ============================\n",
        "    # Resize images\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    resize_criteria = -1\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "        resize_criteria = 0\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "        resize_criteria = 1\n",
        "\n",
        "    kmeans_image = cv2.resize(kmeans_image,\n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    width = round(width * resize_scale)\n",
        "    height = round(height * resize_scale)\n",
        "# =======================================================================\n",
        "\n",
        "    # Pad image\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    if resize_criteria == 0:\n",
        "        pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "        pad_top = pad_height\n",
        "        pad_bottom = pad_height\n",
        "        \n",
        "        total_height = height + (pad_height * 2)\n",
        "\n",
        "        if total_height > NORM_INPUT_H_SIZE:\n",
        "            pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "        elif total_height < NORM_INPUT_H_SIZE:\n",
        "            pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    elif resize_criteria == 1:\n",
        "        pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "\n",
        "        pad_left = pad_width\n",
        "        pad_right = pad_width\n",
        "\n",
        "        total_width = width + (pad_width * 2)\n",
        "\n",
        "        if total_width > NORM_INPUT_W_SIZE:\n",
        "            pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "        elif total_width < NORM_INPUT_W_SIZE:\n",
        "            pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    else:\n",
        "        print(\"Resize Error, [ocurred index] = \", idx)\n",
        "        break\n",
        "    \n",
        "    kmeans_image = cv2.copyMakeBorder(kmeans_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), kmeans_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "OmlRM4vl_CE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## ***실험군 (Color)***"
      ],
      "metadata": {
        "id": "b4bNY2ve_VKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1\n",
        "\n",
        "*적용사항*\n",
        "1. Black boundary 제거\n",
        "2. Lab space의 l, a 채널 CLAHE Contrast 조정\n",
        "3. BGR의 Green channel을 CLAHE Contrast 조정\n",
        "4. Grayscale to Color"
      ],
      "metadata": {
        "id": "ekTS445Q_aY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 384, 512])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.2179\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.2194\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.2210\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.2206\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.2200\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.2581\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.2578\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.2583\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.2557\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.2597\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pgMgnBvt_zRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Process dataset"
      ],
      "metadata": {
        "id": "KJTarpv3_2un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train"
      ],
      "metadata": {
        "id": "DcVd4ZOX_3T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 8:2\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Merge each BGR channel\n",
        "    enhanced_image = cv2.merge((blue_image, green_image, red_image))\n",
        "# =======================================================================\n",
        "\n",
        "    # Pad image\n",
        "    pad_right = int((NORM_INPUT_W_SIZE - width))\n",
        "    pad_bottom = int((NORM_INPUT_H_SIZE - height))\n",
        "\n",
        "    enhanced_image = cv2.copyMakeBorder(enhanced_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), enhanced_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Merge each BGR channel\n",
        "    enhanced_image = cv2.merge((blue_image, green_image, red_image))\n",
        "# =======================================================================\n",
        "\n",
        "    # Pad image\n",
        "    pad_right = int((NORM_INPUT_W_SIZE - width))\n",
        "    pad_bottom = int((NORM_INPUT_H_SIZE - height))\n",
        "\n",
        "    enhanced_image = cv2.copyMakeBorder(enhanced_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), enhanced_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "xoHH9szf_50n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test"
      ],
      "metadata": {
        "id": "mlY9Ekbj_41g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "# ============================== Added code ==============================\n",
        "    # Merge each BGR channel\n",
        "    enhanced_image = cv2.merge((blue_image, green_image, red_image))\n",
        "# =======================================================================\n",
        "\n",
        "    # Pad image\n",
        "    pad_right = int((NORM_INPUT_W_SIZE - width))\n",
        "    pad_bottom = int((NORM_INPUT_H_SIZE - height))\n",
        "\n",
        "    enhanced_image = cv2.copyMakeBorder(enhanced_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), enhanced_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "692qx-fS_6Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2\n",
        "\n",
        "*적용사항*\n",
        "1. Black boundary 제거\n",
        "2. Lab space의 l, a 채널 CLAHE Contrast 조정\n",
        "3. BGR의 Green channel을 CLAHE Contrast 조정\n",
        "4. Top/Bottom/Left/Right 방향으로 bordering to size (384, 512) == (y, x)"
      ],
      "metadata": {
        "id": "lUJ5xTXWXfz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Perfomance\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 384, 512])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  079 /  083 | DICE LOSS  0.2136\n",
        "TRAIN || EPOCH 0020 | BATCH  080 /  083 | DICE LOSS  0.2137\n",
        "TRAIN || EPOCH 0020 | BATCH  081 /  083 | DICE LOSS  0.2129\n",
        "TRAIN || EPOCH 0020 | BATCH  082 /  083 | DICE LOSS  0.2128\n",
        "TRAIN || EPOCH 0020 | BATCH  083 /  083 | DICE LOSS  0.2133\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  017 /  021 | DICE_LOSS  0.2481\n",
        "VALID || EPOCH 0020 | BATCH  018 /  021 | DICE_LOSS  0.2439\n",
        "VALID || EPOCH 0020 | BATCH  019 /  021 | DICE_LOSS  0.2447\n",
        "VALID || EPOCH 0020 | BATCH  020 /  021 | DICE_LOSS  0.2410\n",
        "VALID || EPOCH 0020 | BATCH  021 /  021 | DICE_LOSS  0.2406\n",
        "\n",
        "Best loss in Train each epoch =  0.2133\n",
        "Best loss in Validation each epoch =  0.2372\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "tWWGw0U4X-ym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Process dataset"
      ],
      "metadata": {
        "id": "VZIjN4plYA2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Train"
      ],
      "metadata": {
        "id": "h261ZeJ9YC4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 8:2\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.8)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Merge each BGR channel\n",
        "    enhanced_image = cv2.merge((blue_image, green_image, red_image))\n",
        "\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    enhanced_image = cv2.copyMakeBorder(enhanced_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), enhanced_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Merge each BGR channel\n",
        "    enhanced_image = cv2.merge((blue_image, green_image, red_image))\n",
        "\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    enhanced_image = cv2.copyMakeBorder(enhanced_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), enhanced_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "WFlqU7MvYFY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test"
      ],
      "metadata": {
        "id": "rIrDNlMpYCmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    l_image = l_clahe.apply(l_image)\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Split each BGR\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Merge each BGR channel\n",
        "    enhanced_image = cv2.merge((blue_image, green_image, red_image))\n",
        "\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    enhanced_image = cv2.copyMakeBorder(enhanced_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "    \n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), enhanced_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)"
      ],
      "metadata": {
        "id": "4GwP1RW3YF0F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LAOzIhbp7gxx",
        "MGnC5SL1dPQA",
        "gLWJZjY_BBP9",
        "SIYSvyIfg37Q",
        "S9izC65bg7vV",
        "fJnrN--ao5xc",
        "ox2kye1-smhP",
        "BJhV03IK2RTj",
        "R8DC7EAS_A4T",
        "KJTarpv3_2un",
        "VZIjN4plYA2X"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO9QRBnmMoP8qst8gUpM9DG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
