{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/image-processing/blob/feature%2FPreprocessing/Preprocessor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install**"
      ],
      "metadata": {
        "id": "rmvVB2P2aWlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZNy7tJjaUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_SoWfFhxL0-"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpg4AUPixNrD"
      },
      "outputs": [],
      "source": [
        "# Image processing\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "\n",
        "# ETC\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OHL2n1YxlH_"
      },
      "source": [
        "## Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxOqA3DpxlgC",
        "outputId": "febeeb72-ed13-4085-f5e2-e4458a97c26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqwTBfCyxm3v",
        "outputId": "a20b22a5-7d6d-4150-d7ad-b1e4116eb4d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\n",
            "total 12581\n",
            "drwx------ 2 root root     4096 Sep 14 08:50 'Case Report'\n",
            "drwx------ 2 root root     4096 Aug 16 08:53  Dataset\n",
            "drwx------ 2 root root     4096 Sep 25 16:33 '# Lagacy'\n",
            "drwx------ 2 root root     4096 Aug 17 05:49  Log\n",
            "-rw------- 1 root root  2079705 Oct  5 09:52 '[Model Tester] Down Sampling.ipynb'\n",
            "-rw------- 1 root root    97579 Oct  6 19:41  Preprocessor.ipynb\n",
            "drwx------ 2 root root     4096 Sep 14 06:04 'Raw Dataset'\n",
            "-rw------- 1 root root 10684905 Oct  6 19:38 'Surgical-Wound UNet.ipynb'\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoO0sORTxEIQ"
      },
      "source": [
        "# **Grobal variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9c_qcr4xHQR"
      },
      "outputs": [],
      "source": [
        "# Path (Absolute path in essential)\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\"\n",
        "\n",
        "RAW_DATA_PATH = \"/Raw Dataset\"\n",
        "\n",
        "WOUND_TRAIN_PATH = \"/Wound/train\"\n",
        "WOUND_TEST_PATH = \"/Wound/test\"\n",
        "CVC_INPUT_PATH = \"/CVC-clinicDB/Original\"\n",
        "CVC_GT_PATH = \"/CVC-clinicDB/Ground Truth\"\n",
        "\n",
        "DATASET_PATH = \"/Dataset\"\n",
        "\n",
        "IMAGES_PATH = '/images'\n",
        "LABELS_PATH = '/labels'\n",
        "\n",
        "# Image preprocess\n",
        "NORM_INPUT_W_SIZE = 224\n",
        "NORM_INPUT_H_SIZE = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttpnk92dc7Je"
      },
      "source": [
        "# **Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pYDBzLPc8W2"
      },
      "outputs": [],
      "source": [
        "def imshow_waitkey_enter(image):\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    input(\"Please press the Enter key to proceed\\n\")\n",
        "    output.clear()\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9mVlktdB-A"
      },
      "source": [
        "# **Make dir**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3JXzvP6dDFA"
      },
      "outputs": [],
      "source": [
        "# Create processed dataset dir\n",
        "train_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'train')\n",
        "val_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'val')\n",
        "test_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'test')\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4AWru7Aflb"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# **Preprocess Performace Compare Test**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "***공통사항***\n",
        "* 원본 이미지 크기 = 224 * 224\n",
        "* epoch = 100\n",
        "* batch = 64\n",
        "> UNet batch size = 4<br>\n",
        "> Wound dataset batch size = 8\n",
        "* lr = 1e-3\n",
        "* Train:Val = 7:3\n",
        "* Used model = UNet\n",
        "<br>\n",
        "\n",
        "***주의사항***\n",
        "* 이미지의 사이즈는 정규화 되어야 한다.\n",
        "* Convolution에서 특징점을 잘 추출하기 때문에 색상영역이나, 스무딩/샤프닝 같은 필터 처리는 되려 성능저하 요소가 될 수 있다. \n",
        "\n",
        "<br>\n",
        "\n",
        "***참고사항***\n",
        "* CNN 대표 모델들의 네트워크 입력 사이즈는 224 * 224\n",
        "* 이미지의 사이즈가 큰 경우에, Overlap-Tite(down sampling) 전략으로 한 이미지를 나눠서 학습시킨다.\n",
        "\n",
        "<br>\n",
        "\n",
        "***현재 결과***\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## [***Control Group***](https://www.nature.com/articles/s41598-020-78799-w)\n",
        "> [Train code](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/train.py)\n",
        "> <br>\n",
        "> [Data generator](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/utils/io/data.py#L10)\n",
        "> <br>"
      ],
      "metadata": {
        "id": "iuMgswybTBIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance\n",
        "\n",
        "* Epoch: 200\n",
        "* Batch Size: 64\n",
        "* LR: 1e-3\n",
        "* Optimizer: Adam\n",
        "* loss: Dice loss\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "Best TEST || DICE_LOSS 0.1305\n",
        "\n",
        "Best loss in Train (epoch 199, loss 0.0966)\n",
        "Best loss in Val(Lastest save model) (epoch 194, loss 0.1231)\n",
        "\n",
        "Train std =  0.2151\n",
        "Val std =  0.2475\n",
        "```"
      ],
      "metadata": {
        "id": "d8_SlWxvUPng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Arrange dataset\n",
        "> Not change anything about input image(scar)"
      ],
      "metadata": {
        "id": "LAOzIhbp7gxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "UdLe04Tt7MDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## ***Exprimental Group***"
      ],
      "metadata": {
        "id": "bmjPEH1oS85i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 1\n",
        "> 1:1 비율 변환"
      ],
      "metadata": {
        "id": "byi-Y9PNTLeq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance\n",
        "\n",
        "* Epoch: 200\n",
        "* Batch Size: 64\n",
        "* LR: 1e-3\n",
        "* Optimizer: Adam\n",
        "* loss: Dice loss\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "Best TEST || DICE_LOSS 0.1377\n",
        "\n",
        "Best loss in Train (epoch 189, loss 0.0876)\n",
        "Best loss in Val(Lastest save model) (epoch 197, loss 0.1311)\n",
        "\n",
        "Train std =  0.1525\n",
        "Val std =  0.2000\n",
        "```"
      ],
      "metadata": {
        "id": "_nTJuZlITSvW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "wlOYJUqaTz_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# Image enhance model\n",
        "#sr = cv2.dnn_superres.DnnSuperResImpl_create()\n",
        "#sr.readModel(PROJECT_PATH + '/superres/models/EDSR_x3.pb')\n",
        "#sr.setModel('edsr', 3)\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "    \n",
        "    # Compare width and height for resize to bigger length\n",
        "    if width > height:\n",
        "        height = width\n",
        "    else:\n",
        "        width = height\n",
        "    \n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (width, height),\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image,\n",
        "                          (width, height),\n",
        "                          interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Init padding val\n",
        "    pad_top = 0\n",
        "    pad_bottom = 0\n",
        "    pad_left = 0\n",
        "    pad_right = 0\n",
        "\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "    \n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "aZILjZebT3ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 2\n",
        "> 중앙점 평행 이동"
      ],
      "metadata": {
        "id": "yDqB6bzKl1so"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance\n",
        "\n",
        "* Epoch: 200\n",
        "* Batch Size: 64\n",
        "* LR: 1e-3\n",
        "* Optimizer: Adam\n",
        "* loss: Dice loss\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "Best TEST || DICE_LOSS 0.1557\n",
        "\n",
        "Best loss in Train (epoch 195, loss 0.0876)\n",
        "Best loss in Val(Lastest save model) (epoch 196, loss 0.1462)\n",
        "\n",
        "Train std =  0.1801\n",
        "Val std =  0.2045\n",
        "```"
      ],
      "metadata": {
        "id": "CJagYwIwmOiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "8Zu8DFJOmfEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "TnxBEgaKmfXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 3\n",
        "> 비율 고정, 최대 크기 변환"
      ],
      "metadata": {
        "id": "Hd0AYlMWl6KO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance\n",
        "\n",
        "* Epoch: 200\n",
        "* Batch Size: 64\n",
        "* LR: 1e-3\n",
        "* Optimizer: Adam\n",
        "* loss: Dice loss\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "Best TEST || DICE_LOSS 0.1744\n",
        "\n",
        "Best loss in Train (epoch 200, loss 0.1075)\n",
        "Best loss in Val(Lastest save model) (epoch 186, loss 0.1600)\n",
        "\n",
        "Train std =  0.1008\n",
        "Val std =  0.1694\n",
        "```"
      ],
      "metadata": {
        "id": "XUHslYaqmRni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "TrWMQVKEmcun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224) in proportion to the maximum ratio\n",
        "    # Calculate resize ratio\n",
        "    resize_scale_w = NORM_INPUT_W_SIZE / width\n",
        "    resize_scale_h = NORM_INPUT_H_SIZE / height\n",
        "\n",
        "    # Decide resize criteria between width and height\n",
        "    if resize_scale_w < resize_scale_h:\n",
        "        resize_scale = resize_scale_w\n",
        "    else:\n",
        "        resize_scale = resize_scale_h\n",
        "\n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "RHT_cJOhmd_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### Case 4\n",
        "> 데이터들의 대각선 길이 평균값으로 대각선 크기 변환"
      ],
      "metadata": {
        "id": "rkXQiI21l7E5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Performance\n",
        "\n",
        "* Epoch: 200\n",
        "* Batch Size: 64\n",
        "* LR: 1e-3\n",
        "* Optimizer: Adam\n",
        "* loss: Dice loss\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "Epoch = 200 / 200\n",
        "\n",
        "Best TEST || DICE_LOSS 0.2339\n",
        "\n",
        "Best loss in Train (epoch 185, loss 0.1036)\n",
        "Best loss in Val(Lastest save model) (epoch 129, loss 0.2387)\n",
        "\n",
        "Train std =  0.2362\n",
        "Val std =  0.2043\n",
        "```"
      ],
      "metadata": {
        "id": "uFbkK-utmSK-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocess"
      ],
      "metadata": {
        "id": "rxo-6RCcmZgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_gt_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "gts_train = os.listdir(train_gt_path)\n",
        "gts_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "gt_test = os.listdir(test_gt_path)\n",
        "gt_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, gt_train, gt_val = train_test_split(inputs_train, gts_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, gt_train))\n",
        "val_dataset = dict(zip(input_val, gt_val))\n",
        "test_dataset = dict(zip(input_test, gt_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "diagonal_lens = []\n",
        "diagonal_cnt = 0\n",
        "\n",
        "# Counting diagonal length\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "    \n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "    \n",
        "    # Calc diagonal\n",
        "    diagonal_len = round(np.sqrt((width**2) + (height**2)))\n",
        "    if diagonal_len not in diagonal_lens:\n",
        "        diagonal_cnt += 1\n",
        "        \n",
        "    diagonal_lens.append(diagonal_len)\n",
        "\n",
        "# Print histogram\n",
        "plt.hist(diagonal_lens, \n",
        "         bins=diagonal_cnt, \n",
        "         edgecolor='black')\n",
        "plt.show()\n",
        "\n",
        "D_LEN = max(diagonal_lens, key=diagonal_lens.count)\n",
        "print(\"최대 빈도 대각선 길이 = \", D_LEN)\n",
        "    \n",
        "# Init\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed wound image\n",
        "for input, gt in train_dataset.items(): \n",
        "    # Access wound image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access ground-truth image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt, cv2.IMREAD_GRAYSCALE)\n",
        "    \n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    gt_image = gt_image[y:y+height, x:x+width]\n",
        "    \n",
        "    # Calc diagonal\n",
        "    diagonal_len = round(np.sqrt((width**2) + (height**2)))\n",
        "    \n",
        "    # Calc resize rate\n",
        "    resize_scale = D_LEN / diagonal_len\n",
        "    \n",
        "    # Resize\n",
        "    image = cv2.resize(image,\n",
        "                        (0, 0),\n",
        "                        fx=resize_scale,\n",
        "                        fy=resize_scale,\n",
        "                        interpolation=cv2.INTER_CUBIC)\n",
        "    gt_image = cv2.resize(gt_image, \n",
        "                             (0, 0),\n",
        "                             fx=resize_scale,\n",
        "                             fy=resize_scale,\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        " \n",
        "    # Get height and width\n",
        "    height, width = gt_image.shape\n",
        "\n",
        "    # 3. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_bottom = NORM_INPUT_H_SIZE - height\n",
        "    pad_right = NORM_INPUT_W_SIZE - width\n",
        "    \n",
        "    # Padding\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    gt_image = cv2.copyMakeBorder(gt_image,\n",
        "                               0,\n",
        "                               pad_bottom,\n",
        "                               0,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write train wound image\")\n",
        "    if not cv2.imwrite(os.path.join(train_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write train ground-truth image\")\n",
        "        \n",
        "    idx += 1\n",
        "    \n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write val wound image\")\n",
        "    if not cv2.imwrite(os.path.join(val_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write val ground-truth image\")\n",
        "\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, gt in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_gt_path)\n",
        "    gt_image = cv2.imread(gt)\n",
        "\n",
        "    # Save normalized image\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'wound_{idx:03d}.png'), image):\n",
        "        raise Exception(\"Could not write test wound image\")\n",
        "    if not cv2.imwrite(os.path.join(test_dir, f'gt_{idx:03d}.png'), gt_image):\n",
        "        raise Exception(\"Could not write test ground-truth image\")\n",
        "        \n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "04zHb5hCmb8U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LAOzIhbp7gxx",
        "wlOYJUqaTz_h",
        "8Zu8DFJOmfEw",
        "TrWMQVKEmcun",
        "rxo-6RCcmZgN"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN8jKJsxk6EZke0HmBMiYXk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}