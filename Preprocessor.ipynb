{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/image-processing/blob/feature%2FPreprocessing/Preprocessor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install**"
      ],
      "metadata": {
        "id": "rmvVB2P2aWlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LZNy7tJjaUz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_SoWfFhxL0-"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xpg4AUPixNrD"
      },
      "outputs": [],
      "source": [
        "# Image processing\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "\n",
        "# ETC\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OHL2n1YxlH_"
      },
      "source": [
        "## Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxOqA3DpxlgC",
        "outputId": "24db0ef4-b9ad-46dc-9449-eb70f2b56943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqwTBfCyxm3v",
        "outputId": "01323837-eb8b-48ec-82d5-fdf8cd25340b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/gdrive/MyDrive/Models/GAN_Scar'\n",
            "/content\n",
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Sep 15 11:21 .\n",
            "drwxr-xr-x 1 root root 4096 Sep 15 11:17 ..\n",
            "drwxr-xr-x 4 root root 4096 Sep  9 13:21 .config\n",
            "drwx------ 5 root root 4096 Sep 15 11:21 gdrive\n",
            "drwxr-xr-x 1 root root 4096 Sep  9 13:22 sample_data\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Models/GAN_Scar\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoO0sORTxEIQ"
      },
      "source": [
        "# **Grobal variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Z9c_qcr4xHQR"
      },
      "outputs": [],
      "source": [
        "# Path\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/Models/Surgical-Wound_Segmentation\"\n",
        "\n",
        "RAW_DATA_PATH = \"/Raw Dataset\"\n",
        "\n",
        "WOUND_TRAIN_PATH = \"/Wound/train\"\n",
        "WOUND_TEST_PATH = \"/Wound/test\"\n",
        "CVC_INPUT_PATH = \"/CVC-clinicDB/Original\"\n",
        "CVC_GT_PATH = \"/CVC-clinicDB/Ground Truth\"\n",
        "\n",
        "DATASET_PATH = \"/Dataset\"\n",
        "\n",
        "IMAGES_PATH = '/images'\n",
        "LABELS_PATH = '/labels'\n",
        "\n",
        "# Image preprocess\n",
        "NORM_INPUT_W_SIZE = 224\n",
        "NORM_INPUT_H_SIZE = 224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttpnk92dc7Je"
      },
      "source": [
        "# **Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8pYDBzLPc8W2"
      },
      "outputs": [],
      "source": [
        "def imshow_waitkey_enter(image):\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    input(\"Please press the Enter key to proceed\\n\")\n",
        "    output.clear()\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9mVlktdB-A"
      },
      "source": [
        "# **Make dir**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c3JXzvP6dDFA"
      },
      "outputs": [],
      "source": [
        "# Create processed dataset dir\n",
        "train_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'train')\n",
        "val_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'val')\n",
        "test_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'test')\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4AWru7Aflb"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "# ***Preprocess Performace Compare Test***\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "***공통사항***\n",
        "* 원본 이미지 크기 = 224 * 224\n",
        "* epoch = 100\n",
        "* batch = 8\n",
        "> UNet batch size = 4<br>\n",
        "> Wound dataset batch size = 8\n",
        "* lr = 1e-3\n",
        "* Train:Val = 7:3\n",
        "* Used model = Polar Res UNet++ (ISIC 2018 dice scroe rank no.1)\n",
        "\n",
        "<br>\n",
        "\n",
        "***주의사항***\n",
        "* 이미지의 사이즈는 정규화 되어야 한다.\n",
        "* Convolution에서 특징점을 잘 추출하기 때문에 색상영역이나, 스무딩/샤프닝 같은 필터 처리는 되려 성능저하 요소가 될 수 있다. \n",
        "\n",
        "<br>\n",
        "\n",
        "***참고사항***\n",
        "* CNN 대표 모델들의 네트워크 입력 사이즈는 224 * 224\n",
        "* 이미지의 사이즈가 큰 경우에, Overlap-Tite(down sampling) 전략으로 한 이미지를 나눠서 학습시킨다.\n",
        "\n",
        "<br>\n",
        "\n",
        "***현재 결과***\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## [***Control Group***](https://www.nature.com/articles/s41598-020-78799-w)\n",
        "> [Train code](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/train.py)\n",
        "> <br>\n",
        "> [Data generator](https://github.com/uwm-bigdata/wound-segmentation/blob/de3b9c00974b065b2062fd5cd2efe670da1f8f51/utils/io/data.py#L10)\n",
        "> <br>\n",
        "> <br>\n",
        "> Raw dataset에 대한 전처리 없이, load 후 model에 들어가기 전에 Normalize\n",
        "> <br>\n",
        "> * 현재까지 대조군 성능을 넘은 실험군이 없다.\n",
        "\n",
        "```\n",
        "model = Deeplabv3(input_shape=(input_dim_x, input_dim_y, 3), classes=1)\n",
        "```"
      ],
      "metadata": {
        "id": "iuMgswybTBIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "d8_SlWxvUPng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Grayscale**\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1168\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1192\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1188\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1189\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1205\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.1912\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.1905\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.1893\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.1957\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.1981\n",
        "\n",
        "Best loss in Train =  0.1101\n",
        "Best loss in Validation =  0.1374\n",
        "```"
      ],
      "metadata": {
        "id": "ZcHnKS6nDVmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val Graph***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1AnFMpx_n_TaeY5VnL4f5ztw3uo-HmLLq\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "##### ***Train/Val result image***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1Ek3gu_fT0nKRsxU48MY-v2kvGIDXtSIp\"  width = 640>"
      ],
      "metadata": {
        "id": "SObDmMf_EH7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Color**\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 3, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0100 | BATCH  069 /  073 | DICE LOSS  0.1172\n",
        "TRAIN || EPOCH 0100 | BATCH  070 /  073 | DICE LOSS  0.1171\n",
        "TRAIN || EPOCH 0100 | BATCH  071 /  073 | DICE LOSS  0.1168\n",
        "TRAIN || EPOCH 0100 | BATCH  072 /  073 | DICE LOSS  0.1162\n",
        "TRAIN || EPOCH 0100 | BATCH  073 /  073 | DICE LOSS  0.1158\n",
        "\n",
        "VALID || EPOCH 0100 | BATCH  028 /  032 | DICE LOSS  0.1384\n",
        "VALID || EPOCH 0100 | BATCH  029 /  032 | DICE LOSS  0.1382\n",
        "VALID || EPOCH 0100 | BATCH  030 /  032 | DICE LOSS  0.1380\n",
        "VALID || EPOCH 0100 | BATCH  031 /  032 | DICE LOSS  0.1391\n",
        "VALID || EPOCH 0100 | BATCH  032 /  032 | DICE LOSS  0.1374\n",
        "\n",
        "Best loss in Train =  0.1017\n",
        "Best loss in Validation =  0.1102\n",
        "```"
      ],
      "metadata": {
        "id": "EgfvjWMBDSD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ***Train/Val Graph***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1Pwo0j2qVIk6RBU3JS_aCIa27lRRN4od2\"  width = 320>\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "<br>\n",
        "\n",
        "##### ***Train/Val result image***\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1XO3EJEbRbi_HEB7QpsuX-L-RhpE7K1Fk\"  width = 640>"
      ],
      "metadata": {
        "id": "Sy-K9hGPCUCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arrange dataset\n",
        "> Not change anything about input image(scar)"
      ],
      "metadata": {
        "id": "LAOzIhbp7gxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "labels_train = os.listdir(train_label_path)\n",
        "labels_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "label_test = os.listdir(test_label_path)\n",
        "label_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, label_train, label_val = train_test_split(inputs_train, labels_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, label_train))\n",
        "val_dataset = dict(zip(input_val, label_val))\n",
        "test_dataset = dict(zip(input_test, label_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "UdLe04Tt7MDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "## ***Experimental Group***"
      ],
      "metadata": {
        "id": "sHPbY0FsOzj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 1\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Scar Image to (224, 224)"
      ],
      "metadata": {
        "id": "QcitBtU5PAHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "labels_train = os.listdir(train_label_path)\n",
        "labels_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "label_test = os.listdir(test_label_path)\n",
        "label_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, label_train, label_val = train_test_split(inputs_train, labels_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, label_train))\n",
        "val_dataset = dict(zip(input_val, label_val))\n",
        "test_dataset = dict(zip(input_test, label_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Resize image to (224, 224)\n",
        "    # Resize input image\n",
        "    image = cv2.resize(image,\n",
        "                       (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                       interpolation=cv2.INTER_CUBIC)\n",
        "    \n",
        "    # Resize label image\n",
        "    label_image = cv2.resize(label_image, \n",
        "                             (NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE),\n",
        "                             interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "ON4nZrW6OWjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 2\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Pad the rest part to (224, 224) based on the middle of the image"
      ],
      "metadata": {
        "id": "ZzgNKc_5QSFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set load image dir path\n",
        "train_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + IMAGES_PATH\n",
        "train_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TRAIN_PATH + LABELS_PATH\n",
        "test_image_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + IMAGES_PATH\n",
        "test_label_path = MODEL_PATH + RAW_DATA_PATH + WOUND_TEST_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw input images for Train\n",
        "inputs_train = os.listdir(train_image_path)\n",
        "inputs_train.sort()\n",
        "\n",
        "# Load raw label images for Train\n",
        "labels_train = os.listdir(train_label_path)\n",
        "labels_train.sort()\n",
        "\n",
        "# Load raw input images for Test\n",
        "input_test = os.listdir(test_image_path)\n",
        "input_test.sort()\n",
        "\n",
        "# Load raw label images for Test\n",
        "label_test = os.listdir(test_label_path)\n",
        "label_test.sort()\n",
        "\n",
        "# Split train:val:test = 7:3\n",
        "input_train, input_val, label_train, label_val = train_test_split(inputs_train, labels_train, test_size=0.3, random_state=1)\n",
        "\n",
        "# Merge train/val/test set\n",
        "train_dataset = dict(zip(input_train, label_train))\n",
        "val_dataset = dict(zip(input_val, label_val))\n",
        "test_dataset = dict(zip(input_test, label_test))\n",
        "\n",
        "# ================================ Train ================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in train_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ============================== Validation ==============================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in val_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(train_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(train_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1\n",
        "\n",
        "# ================================= Test =================================\n",
        "# Init image index\n",
        "idx = 0\n",
        "\n",
        "# Create preprocessed scar image\n",
        "for input, label in test_dataset.items(): \n",
        "    # Access input image\n",
        "    os.chdir(test_image_path)\n",
        "    image = cv2.imread(input)\n",
        "\n",
        "    # Access label image\n",
        "    os.chdir(test_label_path)\n",
        "    label_image = cv2.imread(label)\n",
        "\n",
        "    # 1. Cut black boundary on value image\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    # Crop ROI\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # 2. Pad image to (224, 224)\n",
        "    # Calculate padding size\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    # Modify error\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "    \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_H_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_H_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_W_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_W_SIZE - total_width)\n",
        "\n",
        "    # Resizing\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Save normalized image\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    idx += 1"
      ],
      "metadata": {
        "id": "YwmhVRrxOXMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 3\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Scar Image to (224, 224) in proportion to the maximum ratio\n",
        "3. Pad the rest part to (224, 224) in the direction of right/down "
      ],
      "metadata": {
        "id": "SJ_zsDTRPTNG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vuXr6qGyOXje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 4\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Scar Image to (224, 224) in proportion to the maximum ratio\n",
        "3. Pad the rest part to (224, 224) based on the middle of the image"
      ],
      "metadata": {
        "id": "Lm8__jJHPrdC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T8N95OYCOX6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case 5\n",
        "\n",
        "1. Delete Black Boundary(Padding)\n",
        "2. Resize Scar Image to 224 based on the smaller size(row or column), keeping the proportion\n",
        "3. Sampling by moving the kernel both on input and label, Then merge it to fit the label and input pair"
      ],
      "metadata": {
        "id": "apS4MTgAQaez"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZOrpZ1h7OYZx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZcHnKS6nDVmW",
        "EgfvjWMBDSD0",
        "LAOzIhbp7gxx"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyMlospypGfILYavsC1arSG5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}