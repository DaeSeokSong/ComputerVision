{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaeSeokSong/image-processing/blob/feature%2FUnet-scar/Processor_PerformanceTester_Scar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_SoWfFhxL0-"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpg4AUPixNrD"
      },
      "outputs": [],
      "source": [
        "# Image processing\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output\n",
        "\n",
        "# ETC\n",
        "import os\n",
        "import time\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OHL2n1YxlH_"
      },
      "source": [
        "## Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxOqA3DpxlgC",
        "outputId": "65a22035-48d6-4c0d-9c30-1fbc35643fc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqwTBfCyxm3v",
        "outputId": "c66f4785-fbee-400f-f247-6e7fcb3f6003"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Models/GAN_Scar\n",
            "total 10808\n",
            "drwx------ 2 root root     4096 Aug 16 08:53  Dataset\n",
            "-rw------- 1 root root    86402 Aug 13 09:16  Image_segmentation-Scar.ipynb\n",
            "drwx------ 2 root root     4096 Aug 17 05:49  Log\n",
            "-rw------- 1 root root    34357 Aug 29 12:07  Processor_PerformanceTester-Scar.ipynb\n",
            "drwx------ 2 root root     4096 Aug 16 08:39  Raw_Dataset\n",
            "-rw------- 1 root root      391 Aug 24 11:04  RawDataset_Processor-Scar.ipynb\n",
            "drwx------ 2 root root     4096 Aug 23 14:47  result\n",
            "-rw------- 1 root root    39995 Aug 15 11:40 'UNet architecture.PNG'\n",
            "-rw------- 1 root root 10887845 Aug 29 11:52  Unet-Scar.ipynb\n"
          ]
        }
      ],
      "source": [
        "%cd /content/gdrive/MyDrive/Models/GAN_Scar\n",
        "!ls -al"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoO0sORTxEIQ"
      },
      "source": [
        "# **Grobal variable**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9c_qcr4xHQR"
      },
      "outputs": [],
      "source": [
        "# Path\n",
        "MODEL_PATH = \"/content/gdrive/MyDrive/Models/GAN_Scar\"\n",
        "\n",
        "RAW_TRAIN_SET_PATH = \"/Raw_Dataset/train\"\n",
        "RAW_TEST_SET_PATH = \"/Raw_Dataset/test\"\n",
        "\n",
        "DATASET_PATH = \"/Dataset\"\n",
        "\n",
        "IMAGES_PATH = '/images'\n",
        "LABELS_PATH = '/labels'\n",
        "\n",
        "# Image preprocess\n",
        "NORM_INPUT_W_SIZE = 572\n",
        "NORM_INPUT_H_SIZE = 572"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttpnk92dc7Je"
      },
      "source": [
        "# **Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pYDBzLPc8W2"
      },
      "outputs": [],
      "source": [
        "def resize_image(image):\n",
        "    image = cv2.resize(image, \n",
        "                       dsize=(NORM_INPUT_W_SIZE, NORM_INPUT_H_SIZE), \n",
        "                       interpolation=cv2.INTER_CUBIC\n",
        "                       )\n",
        "    \n",
        "    return image\n",
        "\n",
        "def imshow_waitkey_enter(image):\n",
        "    cv2_imshow(image)\n",
        "\n",
        "    time.sleep(0.5)\n",
        "    \n",
        "    input(\"Please press the Enter key to proceed\\n\")\n",
        "    output.clear()\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9mVlktdB-A"
      },
      "source": [
        "# **Make dir**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3JXzvP6dDFA"
      },
      "outputs": [],
      "source": [
        "# Create processed dataset dir\n",
        "train_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'train')\n",
        "val_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'val')\n",
        "test_dir = os.path.join(MODEL_PATH + DATASET_PATH, 'test')\n",
        "\n",
        "if not os.path.exists(train_dir):\n",
        "    os.makedirs(train_dir)\n",
        "\n",
        "if not os.path.exists(val_dir):\n",
        "    os.makedirs(val_dir)\n",
        "\n",
        "if not os.path.exists(test_dir):\n",
        "    os.makedirs(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BULUcWpAkUIK"
      },
      "source": [
        "# 사용 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhiroA0ykUDr"
      },
      "source": [
        "## UNet (Custom)\n",
        "\n",
        "**마지막 Output 채널 2 → 1 변경**\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=14CzAAaKv5v7pVfvugBRbD1xI4IuhmoyT\"  width = 640>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4AWru7Aflb"
      },
      "source": [
        "# ***데이터셋 학습 비교 실험***\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*공통사항*\n",
        "* 원본 이미지 크기 = 244 * 244\n",
        "* epoch = 20\n",
        "* batch = 8 (UNet batch size = 4)\n",
        "* lr = 1e-3\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*주의사항*\n",
        "* 이미지의 사이즈는 정규화 되어야 함\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*참고사항*\n",
        "* CNN 대표 모델들의 네트워크 입력 사이즈는 224 * 224\n",
        "* 이미지의 사이즈가 큰 경우에, Overlap-Tite(down sampling) 전략으로 한 이미지를 나눠서 학습시킨다.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZUKRe7MccGb"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 1\n",
        "\n",
        "*적용사항*\n",
        "1. Lab space를 이용한 Contrast 조정 및 BGR의 Green channel 사용\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 224, 224])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  069 /  073 | LOSS  0.6762\n",
        "TRAIN || EPOCH 0020 | BATCH  070 /  073 | LOSS  0.6762\n",
        "TRAIN || EPOCH 0020 | BATCH  071 /  073 | LOSS  0.6762\n",
        "TRAIN || EPOCH 0020 | BATCH  072 /  073 | LOSS  0.6762\n",
        "TRAIN || EPOCH 0020 | BATCH  073 /  073 | LOSS  0.6762\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  028 /  032 | LOSS  0.6805\n",
        "VALID || EPOCH 0020 | BATCH  029 /  032 | LOSS  0.6805\n",
        "VALID || EPOCH 0020 | BATCH  030 /  032 | LOSS  0.6806\n",
        "VALID || EPOCH 0020 | BATCH  031 /  032 | LOSS  0.6807\n",
        "VALID || EPOCH 0020 | BATCH  032 /  032 | LOSS  0.6805\n",
        "```\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1GOlvg4VIjbExmrc3OK0qB90d1_fFt0Q7\"  width = 400>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1AvmMcgoEUfnPNYgMO4WW6iYiynyJKHE3\"  width = 800>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGnC5SL1dPQA"
      },
      "source": [
        "### Process train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yljPDLtm0zuo"
      },
      "outputs": [],
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 7:3\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.7)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_image = cv2.equalizeHist(l_image)\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    b_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "    b_image = b_clahe.apply(b_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    # val_image는 흑백 이미지라 1채널에 각 픽셀값들도 0~255로 정규화 되어있다.\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    #np.save(os.path.join(train_dir, f'scar_{idx:03d}.npy'), val_image)\n",
        "    #np.save(os.path.join(train_dir, f'label_{idx:03d}.npy'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_image = cv2.equalizeHist(l_image)\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    b_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "    b_image = b_clahe.apply(b_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    # val_image는 흑백 이미지라 1채널에 각 픽셀값들도 0~255로 정규화 되어있다.\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)\n",
        "    #np.save(os.path.join(val_dir, f'scar_{val_idx:03d}.npy'), val_image)\n",
        "    #np.save(os.path.join(val_dir, f'label_{val_idx:03d}.npy'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU5G6MgG25A0"
      },
      "source": [
        "### Process test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIU5Cv4f2wGo"
      },
      "outputs": [],
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_image = cv2.equalizeHist(l_image)\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    b_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "    b_image = b_clahe.apply(b_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    # val_image는 흑백 이미지라 1채널에 각 픽셀값들도 0~255로 정규화 되어있다.\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    #np.save(os.path.join(test_dir, f'scar_{idx:03d}.npy'), val_image)\n",
        "    #np.save(os.path.join(test_dir, f'label_{idx:03d}.npy'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhgq7zplcjoh"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 2\n",
        "\n",
        "*적용사항*\n",
        "1. 불필요 Black boundary 제거\n",
        "2. Lab space를 이용한 Contrast 조정 및 BGR의 Green channel 사용\n",
        "3. Resize to 572*572\n",
        "> UNet 아키텍쳐 입력 이미지 사이즈\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 572, 572])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  069 /  073 | LOSS  0.5164\n",
        "TRAIN || EPOCH 0020 | BATCH  070 /  073 | LOSS  0.5159\n",
        "TRAIN || EPOCH 0020 | BATCH  071 /  073 | LOSS  0.5155\n",
        "TRAIN || EPOCH 0020 | BATCH  072 /  073 | LOSS  0.5150\n",
        "TRAIN || EPOCH 0020 | BATCH  073 /  073 | LOSS  0.5146\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  028 /  032 | LOSS  0.5083\n",
        "VALID || EPOCH 0020 | BATCH  029 /  032 | LOSS  0.5070\n",
        "VALID || EPOCH 0020 | BATCH  030 /  032 | LOSS  0.5049\n",
        "VALID || EPOCH 0020 | BATCH  031 /  032 | LOSS  0.5052\n",
        "VALID || EPOCH 0020 | BATCH  032 /  032 | LOSS  0.5043\n",
        "```\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1uiIqGtvEmYWUhBbjKwjDtncDfg66b1cw\"  width = 400>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1Q5tzGUKwYX5rX4Viy12zHBPukUx1AjtO\"  width = 800>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIYSvyIfg37Q"
      },
      "source": [
        "### Process train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecWAX5SGg4Hw"
      },
      "outputs": [],
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 7:3\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.7)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    if width > height: height = width\n",
        "    else: width = height\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_image = cv2.equalizeHist(l_image)\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    b_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "    b_image = b_clahe.apply(b_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Resize image\n",
        "    green_image = resize_image(green_image)\n",
        "    label_image = resize_image(label_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    # val_image는 흑백 이미지라 1채널에 각 픽셀값들도 0~255로 정규화 되어있다.\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    #np.save(os.path.join(train_dir, f'scar_{idx:03d}.npy'), val_image)\n",
        "    #np.save(os.path.join(train_dir, f'label_{idx:03d}.npy'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    if width > height: height = width\n",
        "    else: width = height\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_image = cv2.equalizeHist(l_image)\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    b_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "    b_image = b_clahe.apply(b_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Resize image\n",
        "    green_image = resize_image(green_image)\n",
        "    label_image = resize_image(label_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    # val_image는 흑백 이미지라 1채널에 각 픽셀값들도 0~255로 정규화 되어있다.\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)\n",
        "    #np.save(os.path.join(val_dir, f'scar_{val_idx:03d}.npy'), val_image)\n",
        "    #np.save(os.path.join(val_dir, f'label_{val_idx:03d}.npy'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9izC65bg7vV"
      },
      "source": [
        "### Process test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BnUptGVg72g"
      },
      "outputs": [],
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    if width > height: height = width\n",
        "    else: width = height\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_image = cv2.equalizeHist(l_image)\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    b_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "    b_image = b_clahe.apply(b_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Resize image\n",
        "    green_image = resize_image(green_image)\n",
        "    label_image = resize_image(label_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    # val_image는 흑백 이미지라 1채널에 각 픽셀값들도 0~255로 정규화 되어있다.\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    #np.save(os.path.join(test_dir, f'scar_{idx:03d}.npy'), val_image)\n",
        "    #np.save(os.path.join(test_dir, f'label_{idx:03d}.npy'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWxTg5BSop6e"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## 3\n",
        "\n",
        "*적용사항*\n",
        "1. Black boundary 모두 제거\n",
        "2. Lab space를 이용한 Contrast 조정 및 BGR의 Green channel 사용\n",
        "3. Bordering(cv2.copymakeborder CONSTANT) to 572*572\n",
        "> UNet 아키텍쳐 입력 이미지 사이즈\n",
        "\n",
        "```\n",
        "Input size =  torch.Size([8, 1, 572, 572])\n",
        "\n",
        "TRAIN || EPOCH 0020 | BATCH  069 /  073 | LOSS  0.3800\n",
        "TRAIN || EPOCH 0020 | BATCH  070 /  073 | LOSS  0.3800\n",
        "TRAIN || EPOCH 0020 | BATCH  071 /  073 | LOSS  0.3800\n",
        "TRAIN || EPOCH 0020 | BATCH  072 /  073 | LOSS  0.3800\n",
        "TRAIN || EPOCH 0020 | BATCH  073 /  073 | LOSS  0.3800\n",
        "\n",
        "VALID || EPOCH 0020 | BATCH  028 /  032 | LOSS  0.3811\n",
        "VALID || EPOCH 0020 | BATCH  029 /  032 | LOSS  0.3811\n",
        "VALID || EPOCH 0020 | BATCH  030 /  032 | LOSS  0.3811\n",
        "VALID || EPOCH 0020 | BATCH  031 /  032 | LOSS  0.3810\n",
        "VALID || EPOCH 0020 | BATCH  032 /  032 | LOSS  0.3810\n",
        "```\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=170ISySZSU8JKrOss--9rPujTHRf7TI0i\"  width = 400>\n",
        "\n",
        "<img src = \"https://drive.google.com/uc?id=1g3Wbe6ym3VK0srroYD-bnwSbMy9QYLW5\"  width = 800>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJnrN--ao5xc"
      },
      "source": [
        "### Process train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBf58SJVo5SY"
      },
      "outputs": [],
      "source": [
        "# Set load image dir path\n",
        "image_path = MODEL_PATH + RAW_TRAIN_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TRAIN_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "train_files = os.listdir(image_path)\n",
        "train_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "train_label_files = os.listdir(label_path)\n",
        "train_label_files.sort()\n",
        "\n",
        "# Divide train:val = 7:3\n",
        "dataset_size = len(train_files)\n",
        "train_size = int(dataset_size * 0.7)\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(train_size): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_W_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_W_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_H_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_H_SIZE - total_width)\n",
        "\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_image = cv2.equalizeHist(l_image)\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    b_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "    b_image = b_clahe.apply(b_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    # val_image는 흑백 이미지라 1채널에 각 픽셀값들도 0~255로 정규화 되어있다.\n",
        "    cv2.imwrite(os.path.join(train_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(train_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    #np.save(os.path.join(train_dir, f'scar_{idx:03d}.npy'), val_image)\n",
        "    #np.save(os.path.join(train_dir, f'label_{idx:03d}.npy'), label_image)\n",
        "\n",
        "# Create processed scar image for validation\n",
        "for val_idx, idx in enumerate(range(train_size, dataset_size)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(train_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(train_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_W_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_W_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_H_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_H_SIZE - total_width)\n",
        "\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_image = cv2.equalizeHist(l_image)\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    b_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "    b_image = b_clahe.apply(b_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    # val_image는 흑백 이미지라 1채널에 각 픽셀값들도 0~255로 정규화 되어있다.\n",
        "    cv2.imwrite(os.path.join(val_dir, f'scar_{val_idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(val_dir, f'label_{val_idx:03d}.png'), label_image)\n",
        "    #np.save(os.path.join(val_dir, f'scar_{val_idx:03d}.npy'), val_image)\n",
        "    #np.save(os.path.join(val_dir, f'label_{val_idx:03d}.npy'), label_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl46mYQto6Dr"
      },
      "source": [
        "### Process test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iGFmaB8Zo6r5"
      },
      "outputs": [],
      "source": [
        "image_path = MODEL_PATH + RAW_TEST_SET_PATH + IMAGES_PATH\n",
        "label_path = MODEL_PATH + RAW_TEST_SET_PATH + LABELS_PATH\n",
        "\n",
        "# Load raw train images\n",
        "os.chdir(image_path)\n",
        "test_files = os.listdir(image_path)\n",
        "test_files.sort()\n",
        "\n",
        "# Load raw label images\n",
        "os.chdir(label_path)\n",
        "test_label_files = os.listdir(label_path)\n",
        "test_label_files.sort()\n",
        "\n",
        "# Create processed scar image for train\n",
        "for idx in range(len(test_files)): \n",
        "    # Access train set\n",
        "    os.chdir(image_path)\n",
        "    image = cv2.imread(test_files[idx])\n",
        "\n",
        "    # Access label set\n",
        "    os.chdir(label_path)\n",
        "    label_image = cv2.imread(test_label_files[idx])\n",
        "\n",
        "    # Get grayscale image\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Cut black boundary on value image\n",
        "    contours, _ = cv2.findContours(gray_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    x, y, width, height = cv2.boundingRect(contours[0])\n",
        "\n",
        "    image = image[y:y+height, x:x+width]\n",
        "    label_image = label_image[y:y+height, x:x+width]\n",
        "\n",
        "    # Pad image\n",
        "    pad_width = int((NORM_INPUT_W_SIZE - width) / 2)\n",
        "    pad_height = int((NORM_INPUT_H_SIZE - height) / 2)\n",
        "\n",
        "    pad_top = pad_height\n",
        "    pad_bottom = pad_height\n",
        "    pad_left = pad_width\n",
        "    pad_right = pad_width\n",
        "\n",
        "    total_height = height + (pad_height * 2)\n",
        "    total_width = width + (pad_width * 2)\n",
        "        \n",
        "    if total_height > NORM_INPUT_H_SIZE:\n",
        "        pad_top = pad_top - (total_height - NORM_INPUT_W_SIZE)\n",
        "    elif total_height < NORM_INPUT_H_SIZE:\n",
        "        pad_bottom = pad_bottom + (NORM_INPUT_W_SIZE - total_height)\n",
        "\n",
        "    if total_width > NORM_INPUT_W_SIZE:\n",
        "        pad_left = pad_left - (total_width - NORM_INPUT_H_SIZE)\n",
        "    elif total_width < NORM_INPUT_W_SIZE:\n",
        "        pad_right = pad_right + (NORM_INPUT_H_SIZE - total_width)\n",
        "\n",
        "    image = cv2.copyMakeBorder(image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,     # method\n",
        "                               value=[0, 0, 0])         # constant value\n",
        "    label_image = cv2.copyMakeBorder(label_image,\n",
        "                               pad_top,\n",
        "                               pad_bottom,\n",
        "                               pad_left,\n",
        "                               pad_right,\n",
        "                               cv2.BORDER_CONSTANT,\n",
        "                               value=[0, 0, 0])\n",
        "\n",
        "    # Equalize histogram used by LAB and BGR color space for make enhanced image \n",
        "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l_image, a_image, b_image = cv2.split(lab_image)\n",
        "\n",
        "    l_image = cv2.equalizeHist(l_image)\n",
        "    a_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    b_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n",
        "    a_image = a_clahe.apply(a_image)\n",
        "    b_image = b_clahe.apply(b_image)\n",
        "\n",
        "    lab_image = cv2.merge((l_image, a_image, b_image))\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "    blue_image, green_image, red_image = cv2.split(enhanced_image)\n",
        "\n",
        "    green_clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(2, 2))\n",
        "    green_image = green_clahe.apply(green_image)\n",
        "\n",
        "    # Save normalized image\n",
        "    # val_image는 흑백 이미지라 1채널에 각 픽셀값들도 0~255로 정규화 되어있다.\n",
        "    cv2.imwrite(os.path.join(test_dir, f'scar_{idx:03d}.png'), green_image)\n",
        "    cv2.imwrite(os.path.join(test_dir, f'label_{idx:03d}.png'), label_image)\n",
        "    #np.save(os.path.join(test_dir, f'scar_{idx:03d}.npy'), val_image)\n",
        "    #np.save(os.path.join(test_dir, f'label_{idx:03d}.npy'), label_image)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "MZUKRe7MccGb",
        "Bhgq7zplcjoh"
      ],
      "name": "Processor_PerformanceTester-Scar.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMPDIZccCC4ye59Am/7LtyY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}